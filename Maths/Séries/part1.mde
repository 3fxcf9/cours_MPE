# Compléments sur les séries

## Séries à valeurs dans un espace vectoriel normé

Dans cette partie, $\K$ représente $\R$ ou $\C$, $(E,\norm \cdot )$ est un $\K$-espace vectoriel normé et $n$ un entier naturel.

Soit l’application
$$
  \varphi: \applic{\ico{n_{0},+\infty}}{\big(E^{\ico{n_{0}, +\infty}}\big)^{2}}{(u_{n})_{n \geq  n_{0}}}{\big((u_{n})_{n \geq  n_{0}}, (S_{n})_{n \geq n_{0}}\big)}
$$
avec pour tout $n \geq  n_{0}$, $S_{n} = \sum_{k=n_{0}}^{n}u_{k}$. C’est une application linéaire injective. $\img \varphi$ est appelé espace vectoriel des séries à valeurs dans $E$. Pour $u \in E^{\ico{n_{0},+\infty}}$, $\varphi(u)$ est noté $\sum_{n \geq n_{0}} u_{n}$ ou encore $\sum u_{n}$.

%def
  $\sum_{n \geq  n_{0}}u_{n}$ est dite convergente dans $(E,\norm \cdot )$ si la suite des sommes partielles $(S_{n})_{n \geq  n_{0}}$ est convergente. Si tel est le cas, on pose $\sum_{n=n_{0}}^{+\infty}u_{n} = \lim_{n\to+\infty} S_{n} \in E$. Ce vecteur est appelé *somme de la série*.
%

%rem
  1. $\sum_{n \geq  n_{0}}u_{n}$ et $\sum_{n \geq  n_{0}+k}$ ont la même nature pour $k \in \N$.
  2. %callout
       Si $\sum_{n \geq n_{0}}u_{n}$ est convergente, alors $S_{n} - S_{n-1} = u_{n} \xrightarrow[n\to+\infty]{\norm\cdot}0_{E}$.
     %
  3. Si $\sum_{n \geq n_{0}}u_{n}$ est convergente, alors on pose $R_{n} = \sum_{k=n+1}^{+\infty}u_{k} \in E$ pour $n \geq  n_{0}+1$. $R_{n}$ est appelé *reste d’ordre $n$* de la série.
  4. %lemma
       $\sum_{n \geq n_{0}}(u_{n+1}-u_{n})$ converge si et seulement si $(u_{n})_{n \geq n_{0}}$ converge.
     %
     %proof
       $S_{n} = \sum_{k=n_{0}}^{n}(u_{k+1}-u_{k}) = u_{n+1} - u_{n_{0}}$ donc $(S_{n})_{n \geq n_{0}}$ converge si et seulement si $(u_{n+1} - u_{n_{0}})_{n \geq n_{0}}$ converge, donc si et seulement si $(u_{n})_{n \geq n_{0}}$ converge.
     %
  5. L’ensemble des séries convergentes à valeurs dans $E$ est un sous-espace vectoriel du $\K$-espace vectoriel des séries à valeurs dans $E$.
     Ainsi, si $\sum_{n \geq n_{0}}u_{n}$ et $\sum_{n \geq n_{0}}v_{n}$ convergent, alors pour tous $(\lambda, \mu) \in \K^{2}$,
     $$
       \sum_{n = n_{0}}^{+\infty}\lambda u_{n} + \mu v_{n} = \lambda \sum_{n=n_{0}}^{+\infty}u_{n} + \mu \sum_{n=n_{0}}^{+\infty}v_{n}
     $$
  6. Deux normes équivalentes sur $E$ donnent la même nature pour une série donnée.
     %callout
       En particulier, en dimension finie, la nature d’une série ne dépend pas de la norme choisie sur $E$.
     %
%

%prop
  Soit $E$ un $\K$-espace vectoriel normé de dimension finie $p \in \N^{*}$. Soit $(e_{1}, \ldots, e_{p})$ une base de $E$. Soit $(u_{n})_{n \in \N} \in E^{\N}$. Posons pour tout $n \in \N$, $u_{n} = u(n) = \sum_{i=1}^{p}u_{i}(n)e_{i}$. Alors la série $\sum_{n \geq 0}u(n)$ est convergente si et seulement si les $p$ séries $\sum_{n \geq 0}u_{i}(n)$ à valeurs dans $\K$ sont convergentes.
  En cas de convergence, on a
  $$
    \sum_{n=0}^{+\infty}u_{n} = \sum_{i=1}^{p}\left(\sum_{n=0}^{+\infty}u_{i}(n)\right)e_{i}
  $$
%

%proof
  $$
    S_{n} = \sum_{k=0}^{n}u(k) = \sum_{k=0}^{n}\left(\sum_{i=1}^{p}u_{i}(k)e_{i}\right) = \sum_{i=1}^{p}\left(\sum_{k=0}^{n}u_{i}(k)\right)e_{i}
  $$
  Alors la suite $(S_{n})_{n \geq 0}$ est convergente dans $E$ si et seulement si les $p$ suites scalaires $\left(\sum_{k=0}^{n}u_{i}(k)\right)_{n \geq 0}$ sont convergentes.
  En cas de convergence, on a
  $$
    \lim_{n\to+\infty}S_{n} = \sum_{i=1}^{p}\left(\lim_{n\to+\infty}\sum_{k=0}^{n}u_{i}(k)\right)e_{i}
  $$
%

%eg
  1. Si $(u_{n})_{n \in \N}$ est une suite à valeurs complexes, $(1,i)$ est une $\R$-base de $\C$ donc en posant pour tout $n \in \N$, $u_{n} = \Re(u_{n})+ i\Im(u_{n})$, on a convergence de $\sum_{n \geq 0}u_{n}$ si et seulement si il y a convergence de $\sum_{n \geq 0}\Re(u_{n})$ et de $\sum_{n \geq 0}\Im(u_{n})$, et en cas de convergence,
     $$
       \sum_{n=0}^{+\infty}u_{n} = \sum_{n=0}^{+\infty}\Re(u_{n}) + i \sum_{n=0}^{+\infty}\Im(u_{n})
     $$
  2. Posons $A = \mtx{\lambda&1&&0\\&\ddots&\ddots&\\&&\ddots& 1\\0&&&\lambda} \in \M_{n}(\C)$ et $\lambda \in \C$. Étudions la nature de $\sum_{n \geq 0}A^{n}$.
     - Si $\sum_{n \geq 0}A^{n}$ converge, alors $A^{n} \arrowlim{n\to+\infty}0_{d}$ donc $\abs{\lambda} < 1$. Supposons donc $\abs{\lambda} < 1$.
     - $A = \lambda I_{d} + N$. Pour tout $n \geq d$, on a
       $$
         A^{n} = (\lambda I_{d} + N)^{n} = \lambda^{n} I_{d} + \binom{n}{1}\lambda^{n-1}N + \cdots + \binom{n}{d-1}\lambda^{n-(d-1)}N^{d-1}
       $$
       La famille $(I_{d}, N, \ldots, N^{d-1})$ est libre dans $\M_{d}(\C)$; on la complète en une base de $\M_{d}(\C)$. Alors $\sum_{n \geq d} A^{n}$ converge si et seulement si les séries coordonnées $\sum_{n \geq d} \lambda^{n}, \sum_{n \geq d}\binom{n}{1}\lambda^{n-1}, \ldots, \sum_{n \geq d}\binom{n}{d-1}\lambda^{n-(d-1)}$ convergent. Soient $k \in \icc{0,d-1}$ et $\lambda \in \C^{*}$. Étudions la convergence de la série $\sum_{n \geq k}\binom{n}{k}\lambda^{n-k}$.
       $$
         \abs{\binom{n}{k}\lambda^{n-k}} \usim{n\to+\infty} \frac{1}{\abs{\lambda}^{k}} \frac{n^{k}}{k!}\abs{\lambda}^{n}
       $$
       Soit $r = \frac{\abs{\lambda} + 1}{2} \in \oo{\abs{\lambda}, 1}$.
       $$
         n^{k} \abs{\lambda}^{n} \ueq{n\to+\infty} o(r^{n})
       $$
       car $n^{k} \left(\frac{\abs{\lambda}}{r}\right)^{n} \arrowlim{n\to+\infty}0$ car $0 \leq \frac{\abs{\lambda}}{r} < 1$. Or $\sum_{n \geq 0}r^{n}$ converge (car $0 \leq  r < 1$), doonc $\sum_{n \geq 0}n^{k} \lambda^{n}$ est absolument convergente, d’où $\sum_{n \geq k}\binom{n}{k}\lambda^{n-k}$ est absolument convergente à laveurs dans $\C$, donc convergente. Ainsi
       $$
         \sum_{n \geq 0} \text{ convergente} \iff  \abs{\lambda} < 1
       $$
       et pour $\abs{\lambda} < 1$, on a
       $$
         \sum_{n=0}^{+\infty} = \sum_{k=0}^{d-1} \left(\sum_{n=k}^{+\infty}\binom{n}{k}\lambda^{n-k}\right)N^{k}
       $$
%

%def
  Soit $(u_{n})_{n \in \N}$ une suite à valeurs dans $(E,\norm \cdot )$. On dit que la série $\sum_{n \geq 0}u_{n}$ est *absolument convergente* si la série à termes positifs $\sum_{n \geq 0}\norm{u_{n}}$ est convergente.
%

%callout Attention
  Dans $\R[X]$, on pose, pour $(a_{k})_{k \in \N}$ une suite réelle,(($\sum_{k \in \N}a_{k} X^{k}$ est un polynôme, $\norm{\sum_{k \in \N}a_{k} X^{k}}$ est donc bien définie.))
  $$
    \norm{\sum_{k \in \N}a_{k} X^{k}} = \sum_{k \in \N} \abs{a_{k}}
  $$
  Considérons la série $S = \sum_{n \geq 0}\frac{X^{n}}{(n+1)^{2}}$. Alors, la série
  $$
    \sum_{n \geq 0}\norm{\frac{X^{n}}{(n+1)^{2}}} = \sum_{n \geq 0}\frac{1}{(n+1)^{2}}
  $$
  converge, donc $S$ est absolument convergente. Supposons que $S$ est convergente. Notons $P = \sum_{k=0}^{d}a_{k}X^{k}$ la somme de la série. Pour $n \geq d+1$,
  $$
    \begin{align*}
      \norm{S_{n} - P} &= \norm{\sum_{k=0}^{n}\frac{X^{k}}{(k+1)^{2}} - \sum_{k=0}^{d}a_{k}X^{k}}\\
       &= \sum_{k=0}^{d}\abs{\frac{1}{(k+1)^{2}} - a_{k}} + \sum_{k=d+1}^{n}\frac{1}{(k+1)^{2}} \geq \frac{1}{(d+2)^{2}}
    \end{align*}
  $$
  donc
  $$
    \forall n \geq d+1, \norm{S_{n} - P} \geq  \frac{1}{(d+2)^{2}}.
  $$
  Par passage à limite, on a
  $$
    0 \geq \frac{1}{(d+2)^{2}}
  $$
  donc $\sum_{n \geq 0}\frac{X^{n}}{(n+1)^{2}}$ est une série **absolument convergente mais divergente**.
%

%prop
  1. Si $N$ et $N'$ sont deux normes équivalentes sur un $\K$-espace vectoriel $E$ et si $(u_{n})_{n \in \N} \in E^{\N}$, alors les séries $\sum N(u_{n})$ et $\sum N'(u_{n})$ ont la même nature.
  2. Si $E$ est un $\K$-espace vectoriel normé de ++dimension finie++, alors ++toute série à valeurs dans $E$ absolument convergente est convergente++.
     %offprog
       On dit qu’un espace vectoriel normé de dimension finie est un *espace de Banach* (ou un espace vectoriel normé *complet*).((Anecdote: M. Schwarz racontait à ses étudianst qu’un jour, il voulait prendre le bus pour la station « Banach » à Varsovie mais celui-ci était complet.))
     %
  3. Si $\dim E < +\infty$ et $\sum_{k \in \N}\norm{u_{k}} < +\infty$, alors $\sum_{k \in \N}u_{k}$ converge, et de plus
     $$
       \norm{\sum_{k=0}^{+\infty}u_{k}} \leq  \sum_{k=0}^{+\infty}\norm{u_{k}}
     $$
     si convergence absolue en dimension finie.
%

%proof
  1. Il existe $\alpha > 0$ et $\beta > 0$ tels que
     $$
       \alpha N \leq  N' \leq  \beta N
     $$
     donc
     $$
       N'(u_{n}) \ueq{n\to+\infty} O(N(u_{n})) \quad\text{et}\quad N(u_{n}) \ueq{n\to+\infty} O(N'(u_{n}))
     $$
  2. Soit $E$ un $\K$-espace vectoriel normé de dimension finie $p \in \N^{*}$. Notons-en $\mathscr B = (e_{1}, \ldots, e_{p})$ une base. Soit $(u_{n})_{n \in \N} \in E^{\N}$ et supposons $\sum_{n \geq 0}u_{n}$ absolument convergente, i.e. $\sum_{n \geq 0}N_{\infty,\mathscr B}(u_{n})$ convergente ($N_{\infty, \mathscr B} = \max_{i \in \icc{1,p}} \abs{x_{i}}$). Soit $x = \sum_{i=1}^{p}x_{i}e_{i}$. Notons pour $n \in \N$, $u_{n} = u(n) = \sum_{i=1}^{p}u_{i}(n)e_{i}$. On a alors
     $$
       \forall i \in \icc{1,p}, \forall n \in \N, \abs{u_{i}(n)} \leq  N_{\infty, \mathscr B}(u(n))
     $$
     donc $\sum_{n \geq 0} \abs{u_{i}(n)}$ converge pour tout $i \in \icc{1,p}$. Or $\K$ est $\K$-espace vectoriel normé complet donc $\sum_{n \geq 0}u_{i}(n)$ converge pour tout $i \in \icc{1,p}$, donc $\sum_{n \geq 0}u(n)$ converge dans $E$.
  3. $\norm{\sum_{k=0}^{N}u_{k}} \leq \sum_{k=0}^{N}\norm{u_{k}}$ puis passage à la limite.
%

%eg
  *Exemple classique:* Soit $(A,+, \times , \cdot )$ une $\K$-algèbre munie d’une norme $\norm \cdot $ sous-multiplicative. Soit $u \in A$ tel que $\norm u < 1$. Étiduons la série $\sum_{k \geq 0}u^{k}$.

  ---

  On a par sous-multiplicité $\forall k \in \N^{*}, \norm{u^{k}} \leq  \norm{u}^{k}$ et $\sum_{k \geq 0} \norm{u}^{k}$ converge car $\norm u \in \co{0,1}$, donc la série $\sum_{k \geq 0}u^{k}$ est absolument convergente. Comme $A$ est de dimension finie, la série $\sum_{k \geq 0}^{u^{k}}$ est convergente.
  $$
    (1_{A} - u) \times \sum_{k=0}^{n}u^{k} = \sum_{k=0}^{n}u^{k} - u^{k+1} = \sum_{k=0}^{n}u^{k} \times (1_{A} - u)
  $$
  or
  $$
    \sum_{k=0}^{n}u^{k} - u^{k+1} = 1_{A} - u^{n+1} \arrowlim{n\to+\infty} 1_{A} - 0_{A} = 1_{A}
  $$
  d’où
  $$
    (1_{A} - u) \times  \sum_{k=0}^{+\infty} u^{k} = 1_{A} = \left(\sum_{k=0}^{+\infty}u^{k}\right) \times (1_{A} - u)
  $$
  d’où $1_{A} - u \in A^{\times}$ et
  $$
    \boxed{\sum_{k=0}^{+\infty}u^{k} = (1_{A} - u)^{-1} \quad\text{pour } \begin{cases}\norm u < 1\\ \norm\cdot \text{ sous-multiplicative}\end{cases}}
  $$
%

%recall
  $$
    \forall  z \in \C, e^{z} = \sum_{n=0}^{+\infty}\frac{z^{n}}{n!}
  $$
  d’où
  $$
    \forall x \in \R, e^{x} = \sum_{n=0}^{+\infty}\frac{x^{n}}{n!} = \sum_{n \in \N}\frac{x^{2n}}{(2n)!} + \sum_{n \in \N}\frac{x^{2n+1}}{(2n+1)!}
  $$
  or
  $$
    x \longmapsto \sum_{n \in \N} \frac{x^{2n}}{(2n)!}
  $$
  est paire (et donc égale à $\ch$) et
  $$
    x \longmapsto \sum_{n \in \N} \frac{x^{2n+1}}{(2n+1)!}
  $$
  est impaire (et donc égale à $\sh$). Ainsi, pour tout $x \in \R$,
  $$
    \boxed{\ch x = \sum_{n=0}^{+\infty}\frac{x^{2n}}{(2n)!}} \quad\text{et}\quad \sh x = \sum_{n=0}^{+\infty}\frac{x^{2n+1}}{(2n+1)!}
  $$
%

%def Proposition-définition
  1. Soit $d \in \N^{*}$. Soit $A \in \M_{d}(\K)$ ($\M_{d}(\K)$ est normé). La série $\sum_{n \geq 0}\frac{A^{n}}{n!}$ est absolument convergente, donc convergente (car $\dim_{\K} \M_{d}(\K) = d^{2} < +\infty$). On appelle *exponentielle de $A$* la matrice
     $$
       \exp(A) = \sum_{n=0}^{+\infty}\frac{A^{n}}{n!}
     $$
  2. Soit $E$ un $\K$-espace vectoriel de dimension $d \in \N^{*}$. Si $\L(E)$ est normé et $u \in \L(E)$, alors la série $\sum_{n \geq 0} \frac{u^{n}}{n!}$ est absolument convergente dans $\L(E)$ donc convergente (car $\dim_{\K}\L(E) = d^{2} < +\infty$). On appelle *exponentielle de $u$* l’endomorphisme
     $$
       \exp(u) = \sum_{n=0}^{+\infty}\frac{u^{n}}{n!} \in \L(E)
     $$
%

%proof
  1. Soit $\norm\cdot$ une norme sous-multiplicative sur $\M_{d}(\K)$((Elle existe: par exemple $A \longmapsto d\max_{1 \leq  i,j \leq d}\abs{a_{i,j}}$.)). On a
     $$
       \forall  n \in \N^{*}, \norm{\frac{A^{n}}{n!}} = \frac{1}{n!} \norm{A^{n}} \leq \frac{\norm{A}^{n}}{n!}
     $$
     or $\sum_{n \geq 0}\frac{\norm{A}^{n}}{n!}$ est une série convergente (de somme $e^{\norm{A}}$) donc $\sum_{n \geq 0}\norm{\frac{A^{n}}{n!}}$ est convergente.
  2. Soit $\mathscr B$ une base de $E$. Soit $\norm \cdot $ une norme sous-multiplicative sur $\M_{d}(\K)$. Par transport de norme via l’isomorphisme
     $$
       \applic{\L(E)}{\M_{d}(\K)}{u}{\mat_{\mathscr B}(u)}
     $$
     $N: u \longmapsto  N(u) = \norm{\mat_{\mathscr B}(u)}$ est une norme sous-multiplicative sur $\L(E)$. Soit $(u,v) \in \big(\L(E)\big)^{2}$:
     $$
       \begin{align*}
         N(u\circ v) &= \norm{\mat_{\B}(u\circ v)} = \norm{\mat_{\mathscr   B} u \times \mat_{\mathscr B}v}\\
         & \leq \norm{\mat_{\mathscr B}(u)} \times  \norm{\mat_{\mathscr B}v} = N(u)\times N(v)
       \end{align*}
     $$
     On a donc
     $$
       \forall n \in \N^{*}, N \left(\frac{u^{n}}{n!}\right) \leq \frac{N(u)^{n}}{n!}
     $$
     d’où l’absolue convergence de la série $\sum_{n \geq 0}\frac{u^{n}}{n!}$.
%

%prop
  1. $\exp(0_{d}) = I_{d}$ donc $\forall \lambda \in \K, \exp(\lambda I_{d}) = e^{\lambda}I_{d}$ d’où
     $$
       \forall (\lambda_{1}, \ldots, \lambda_{d}) \in \K^{d}, \exp(\diag(\lambda_{1}, \ldots, \lambda_{d})) = \diag(e^{\lambda_{1}}, \ldots, e^{\lambda_{d}})
     $$
  2. Pour $(A,B) \in \M_{d}(\K)^{2}$, on a
     $$
       AB = BA \implies  \exp(A+B) = \exp A \times \exp B = \exp B \times \exp A
     $$
  3. $\forall A \in \M_{d}(\K), \exp(A) \in \GL_{d}(\K)$ et pour $A \in \M_{d}(\K)$, on a
     $$
       \exp(A)^{-1} = \exp(-A)
     $$

  Ce qui s’adapte pour les endomorphismes~:
  1. $\exp(0_{\L(E)}) = \id_{E}$ et
     $$
       \forall  \lambda \in \K, \exp(\lambda \id _{E}) = e^{\lambda}\id _{E}
     $$
  2. Pour $(u,v) \in \L(E)^{2}$, on a
     $$
       [u,v] = 0_{\L(E)} \implies  \exp(u+v) = \exp(u)\circ \exp(v) = \exp(v)\circ \exp(u)
     $$
  3. $\forall u \in \L(E), \exp u \in \GL(E)$ et pour $u \in \L(E)$,
     $$
       \exp(u)^{-1} = \exp(-u)
     $$
%

%proof
  1. $\exp(0_{d}) = \sum_{n=0}^{+\infty}\frac{0_{d}^{n}}{n!} = \frac{0_{d}^{0}}{0!} + 0_{d} = I_{d}$ donc
     $$
       \sum_{n=0}^{N}\frac{\diag(\lambda_{1}, \ldots, \lambda_{d})}{n!} = \diag \left(\sum_{n=0}^{N}\frac{\lambda_{1}^{n}}{n!}, \ldots, \sum_{n=0}^{N}\frac{\lambda_{d}^{n}}{n!}\right) \arrowlim{N \to+\infty} \diag(e^{\lambda_{1}}, \ldots, e^{\lambda_{d}})
     $$
     donc $\exp(\diag(\lambda_{1}, \ldots, \lambda_{d})) = \diag(e^{\lambda_{1}}, \ldots, e^{\lambda_{d}})$ d’où $\exp(\lambda\pm d) = e^{\lambda} I_{d}$.
  2. %fold Preuve faite en exercice
       **++Exercice 2++**

       1. Soit $x \in \R$. Déterminer la limite $\lim_{p\to+\infty}\left(1+\frac{x}{p}\right)^{p}$.

          ---

          $1+\frac{x}{p} \arrowlim{p\to+\infty}1$ donc
          $$
            \exists N \in \N: \forall p \geq  N, 1+\frac{x}{p} > 0
          $$
          donc
          $$
            \begin{align*}
              \forall p \geq N, \left(1+\frac{x}{p}\right)^{p} &= e^{p\ln \left(1 + \frac{x}{p}\right)}\\
              &\ueq{+\infty} e^{p \left(\frac{x}{p} + o \left(\frac{1}{p}\right)\right)}\\
              &\ueq{+\infty} e^{x}e^{o(1)} \arrowlim{p\to+\infty}e^{x}
            \end{align*}
          $$
          par continuité de $\exp$ en 0:
          $$
            \boxed{\left(1+\frac{x}{p}\right)^{p} \arrowlim{p\to+\infty} e^{x}} \quad\text{et}\quad \boxed{\left(1+\frac{x}{p}\right)^{-p} \arrowlim{p\to+\infty} e^{-x}}
          $$
       2. Montrer que $A \longmapsto \norm A_{L} = \max_{i \in \icc{1,n}}\sum_{j=1}^{n}\abs{a_{i,j}}$ est une norme sous-multiplicative sur $\M_{n}(\K)$.

          ---

          Il s’agit bien d’une norme. Montrons qu’elle est sous-multiplicative: soient $(A,B) \in \M_{n}(\K)^{2}$. $C = AB = \mtx{c}_{1 \leq i,j \leq n}$.
          $$
            c_{i,j} = \sum_{k=1}^{n}a_{i,k}b_{k,j}
          $$
          donc
          $$
            \abs{c_{i,j}} \leq \sum_{k=1}^{n}\abs{a_{i,k}}\abs{b_{k,j}}
          $$
          Soit $i \in \icc{1,n}$.
          $$
            \begin{align*}
              \sum_{j=1}^{n} \abs{c_{i,j}} &\leq  \sum_{j=1}^{n}\left(\sum_{k=1}^{n}\abs{a_{i,k}}\abs{b_{k,j}}\right)\\
              &\leq \sum_{k=1}^{n}\left( \sum_{j=1}^{n}\cdots\right)
            \end{align*}
          $$
          Ainsi
          $$
            \begin{align*}
              \sum_{j=1}^{n}\abs{a_{i,j}} &\leq \sum_{k=1}^{n}\abs{a_{i,k}}\left(\sum_{j=1}^{n}\abs{b_{k,j}}\right)\\
              &\leq \sum_{k=1}^{n}\abs{a_{i,k}}\norm{B}_{L} = \norm{B}_{L} \sum_{k=1}^{n}\abs{a_{i,k}}\\
              &\leq \norm{A}_{L} \norm{B}_{L}
            \end{align*}
          $$
          donc $\norm{AB}_{L} \leq  \norm{A}_{L} \norm{B}_{L}$. De plus, $\norm{I_{n}} = 1$ donc
          $$
            \forall k \in \N, \norm{A^{k}}_{L} \leq \norm{A}_{L}^{k}
          $$
       3. Soit $A \in \M_{n}(\K)$. En majorant $\norm{\exp(A) - \left(I_{n} + \frac{1}{p}A\right)^{p}}_{L}$, montrer que $\exp(A) = \lim_{p\to+\infty} \left(I_{n} + \frac{1}{p}A\right)^{p}$.

          ---

          $$
            \exp(A) - \left(I_{n} + \frac{1}{p}A\right)^{p} = \sum_{k=1}^{p}\left(\frac{1}{k}- \binom{p}{k}\frac{1}{p_{k}}\right)A^{k} + \sum_{k=p+1}^{+\infty}\frac{A^{k}}{k!}
          $$
          donc
          $$
            \begin{align*}
              \norm{\exp(A) - \left(I_{n} + \frac{1}{p}A\right)^{p}} &\leq  \sum_{k=0}^{p}\underbrace{\abs{\frac{1}{k!} - \binom{p}{k}\frac{1}{p^{k}}}}_{= \frac{1}{k!} - \frac{1}{p^{k}} \frac{p(p-1) \cdots (p-k+1)}{k!}\geq 0}\norm{A}^{k} + \underbrace{\sum_{k=p+1}^{+\infty}\frac{\norm{A}_{L}^{k}}{k!}}_{\text{par absolue convergence de } \sum_{k \geq 0}\frac{A^{k}}{k!}}\\
              &\leq \sum_{k=1}^{p} \left(\frac{1}{k!} - \binom{p}{k} \frac{1}{p^{k}}\right)\norm{A}^{k} + \sum_{k=p+1}^{+\infty}\frac{\norm{N}^{k}}{k!}\\
              &\leq e^{\norm{A}} - \left(1 + \frac{\norm{A}}{p}\right)^{p} \arrowlim{p\to+\infty}0
            \end{align*}
          $$
          donc $\left(I_{n} + \frac{1}{p}A\right)^{p} \arrowlim{p\to+\infty}e^{A}$.

       **++Exercice 3++**

       Soient $(A,B) \in \M_{n}(\K)^{2}$ telles que $AB = BA$. En considérant la différence
       $$
         \left(I_{n} + \frac{1}{p}(A+B) + \frac{1}{p^{2}}AB\right)^{p} - \left(I_{n} + \frac{1}{p}(A+B)\right)^{p}
       $$
       démontrer que $\exp(A+B) = \exp(A)\times \exp(B)$.

       ---

       Notons $C_{p}$ le produit ci-dessus.
       $$
         C_{p} = \sum_{k=0}^{p-1}\binom{p}{k}\left(I_{n} + \frac{1}{p}(A+B)\right)^{k}\left(\frac{1}{p^{2}}AB\right)^{p-k}
       $$
       donc
       $$
         \norm{C_{p}}_{L} \leq \sum_{k=0}^{p-1}\binom{p}{k}\left(1+\frac{1}{p}\norm{A}_{L}\norm{B}_{L}\right)^{k} \left(\frac{1}{p^{2}}\norm{A}_{L}\norm{B}_{L}\right)^{p-k} = \left(1 + \frac{\alpha}{p} + \frac{\beta}{p^{2}}\right)^{p} - \left(1 + \frac{\alpha}{p}\right)^{p}
       $$
       avec $\alpha = \norm{A}_{L}+\norm{B}_{L} \geq$ et $\beta = \norm{A}_{L}\norm{B}_{L} \geq 0$. Ainsi
       $$
         \left(1 + \frac{\alpha}{p} + \frac{\beta}{p^{2}}\right)^{p} = e^{p\ln \left(1 + \frac{\alpha}{p} + \frac{\beta}{p^{2}}\right)} = e^{p \left(\frac{\alpha}{p} + o \left(\frac{1}{p}\right)\right)} = e^{\alpha + o(1)} \arrowlim{p\to+\infty}e^{\alpha}
       $$
       donc
       $$
         C_{p} \arrowlim{p\to+\infty}0_{n} = e^{A}e^{B} - e^{A+B}
       $$
       car $[A,B] = 0_{n}$ donc
       $$
         C_{p} = \left(I_{n} + \frac{A}{p}\right)^{p} \left(I_{n} + \frac{B}{p}\right)^{p} - \left(I_{n} + \frac{A+B}{p}\right)^{p}
       $$
     %
  3. On a $I_{d} = \exp(0_{d}) = \exp(A-A)$. $[A,-A] = 0_{d}$ donc $I_{d} = \exp(A) \times \exp(-A)$. Alors, $\exp(A) \in \GL_{d}(\K)$ et $\exp(A)^{-1} = \exp(-A)$.
%

%eg
  1. Soit $U = \mtx{1}_{(d)} \in \M_{d}(\K)$((Matrice Attila (matrice de Huns) )). $U^{2} = dU$; $U^{3} = dU^{2} = d^{2}U$, etc. donc
     $$
       \forall k \in \N, U^{k+1} = d^{k}U
     $$
     d’où
     $$
       \exp(U) = \sum_{k=0}^{+\infty}\frac{U^{k}}{k!} = I_{d} + \sum_{k=0}^{+\infty} \frac{U^{k+1}}{(k+1)!}
     $$
     Posons la somme partielle
     $$
       S_{N} = \sum_{k=0}^{N}\frac{d^{k}U}{(k+1)!} = \left(\sum_{k=0}^{N}\frac{d^{k}}{(k+1)!}\right)U \arrowlim{N\to+\infty} \left(\sum_{k=0}^{+\infty}\frac{d^{k}}{(k+1)!}\right)U = \frac{1}{d}(e^{d} - 1)U
     $$
  2. Considérons $A = \mtx{0&0\\1&0}$ et $B = \mtx{0&1\\0&0}$. On a $A^{2} = B^{2} = 0_{2}$.
     $$
       \exp(A) = I+A = \mtx{1&0\\1&1} \quad\text{et}\quad \exp(B) = I+B = \mtx{1&1\\0&1}
     $$
     $A+B = \mtx{0&1\\1&0}$ donc $(A+B)^{2} = I_{2}$ d’où
     $$
       \forall k \in \N, \begin{cases}(A+B)^{2k} &= I_{2}\\ (A+B)^{2k+1} &= A+B\end{cases}
     $$
     d’où
     $$
       \begin{align*}
         \exp(A+B) &= \sum_{k=0}^{+\infty}\frac{(A+B)^{k}}{k!}\\
         &= \lim_{N\to+\infty} \left(\sum_{k=0}^{N}\frac{I_{2}}{(2k)!} + \sum_{k=0}^{N}\frac{A+B}{(2k+1)!}\right)\\
         &= \ch(1)I_{2} + \sh(1)(A+B)\\
         &= \mtx{\ch 1 & \sh 1\\\sh 1 & \ch 1}\\
         &\ne \exp A \times \exp B = \mtx{1&1\\1&2}
       \end{align*}
     $$

%

%offprog
  %prop
    Soient $(A,B) \in \M_{d}(\K)^{2}$.
    1. Si $A$ et $B$ sont semblables, alors $e^{A}$ et $e^{B}$ le sont aussi (avec les mêmes matrices de passage)
    2. Si $\chi_{A} = \prod_{i=1}^{d}(X-\lambda_{i})$, alors $\chi_{e^{A}} = \prod_{i=1}^{d}(X-e^{\lambda_{i}})$.
    3. Si $A$ est diagonalisable, alors $e^{A}$ l’est aussi.
    4. $\det (e^{A}) = e^{\tr A}$.
  %

  %rem
    En particulier pour $A \in \M_{d}(\R)$, on a $\det e^{A} > 0$.
    $$
      \exp: \M_{d}(\R) \longrightarrow \GL^{+}_{d}(\R)
    $$
    ($\GL^{+}_{d}(\R) \subset \{A \in \M_{d}(\R) \where \det A > 0\}$)
  %

  %proof
    1. $A = PBP^{-1} \implies  \forall Q \in \K[X], Q(A) = PQ(B)P^{-1}$ donc
       $$
         \forall N \in \N, \sum_{n=0}^{N}\frac{A^{n}}{n!} = P \left(\sum_{n=0}^{N}\frac{B^{n}}{n!}\right)P^{-1}
       $$
       donc par passage à la limite, on a
       $$
         \exp(A) = P\exp(B)P^{-1}
       $$
    2. Si $\chi_{A} = \prod_{i=1}^{d}(X-\lambda_{i})$ dans $\K[X]$, alors $\chi_{A}$ est scindé dans $\K[X]$ donc $A$ est trigonalisable:
       $$
         A = P \underbrace{\mtx{\lambda_{1} & &*\\&\ddots&\\0&&\lambda_{d}}}_{\coloneqq P}P^{-1}
       $$
       d’où $\exp(A) = P \exp(T)P^{-1}$.
       $$
         \begin{align*}
           \exp(T) &= \sum_{n=0}^{+\infty}\frac{T^{n}}{n!}\\
            &=\sum_{n=0}^{+\infty}\frac{1}{n!}\mtx{\lambda_{1} & &*\\&\ddots&\\0&&\lambda_{d}}\\
            &=\mtx{\sum_{n=0}^{+\infty}\frac{\lambda_{i}^{n}}{n!} & &*'\\&\ddots&\\0&& \sum_{n=0}^{+\infty} \frac{\lambda_{d}^{n}}{n!}}\\
            &= \mtx{e^{\lambda_{1}} &&*'\\&\ddots&\\0&& e^{\lambda_{d}}}
         \end{align*}
       $$
       donc
       $$
         \chi_{e^{A}} = \chi_{e^{T}} = \prod_{i=1}^{d}(X-e^{\lambda_{i}})
       $$
    3. Si $A = P\diag(\lambda_{1}, \ldots, \lambda_{d})P^{-1}$, alors
       $$
         \exp A = P \diag(e^{\lambda_{1}}, \ldots, e^{\lambda_{d}})P^{-1}
       $$
    4. Soit $A \in \M_{n}(\K) \subset \M_{n}(\C)$. Si $\chi_{A} = \prod_{i=1}^{d}(X-\lambda_{i})$ dans $\C[X]$, alors $\chi_{e^{A}} = \prod_{i=1}^{d}(X- e^{\lambda_{i}})$, d’où
       $$
         \det (\exp A) = \prod_{i=1}^{d}e^{\lambda_{i}} = e^{\sum_{i=1}^{d}\lambda_{i}}
       $$
       Ainsi, $\det (e^{A}) = e^{\tr A}$.
  %
%

## Séries numériques usuelles

%thm Séreis de Riemann
  Paur $\alpha \in \R$, la série
  $$
    \sum_{n \geq 1}\frac{1}{n^{\alpha}}
  $$
  converge si et seulement si $\alpha > 1$.
%

%cor
  Pour $(u_{n})_{n \in \N}$ une suite complexe,
  - si $\alpha > 1$ et si $u_{n} = O \left(\frac{1}{p^{\alpha}}\right)$, alors $\sum_{n \geq 0}\abs{u_{n}}$ converge
  - si $\alpha < 1$ et $\frac{1}{n^{\alpha}} = O(u_{n})$, alors $\sum_{n \geq 0}\abs{u_{n}}$ diverge.
%

%offprog
  %thm Séries de Bertrand
    Pour $(\alpha, \beta) \in \R^{2}$, la série
    $$
      \sum_{n \geq 2}\frac{a}{n^{\alpha} \big(\ln n\big)^{\beta}}
    $$
    converge st et seulement si $\alpha > 1$ ou $\begin{cases}\alpha=1\\ \beta > 1\end{cases}$.
  %
  %proof
    - si $\alpha < 0$,
      $$
        \frac{1}{n^{\alpha}(\ln n)^{\beta}} = \frac{n^{-\alpha}}{(\ln n)^{\beta}}\arrowlim{n\to+\infty}+\infty
      $$
      donc la série est grossièrement divergente.
    - si $\alpha \in \co{0,1}$,
      $$
        n\frac{1}{n^{\alpha}(\ln n)^{\beta}} = \frac{n^{1-\alpha}}{(\ln n)^{\beta}}\arrowlim{n\to+\infty} +\infty
      $$
      donc
      $$
        \frac{1}{n} = O \left(\frac{1}{n^{\alpha}(\ln n)^{\beta}}\right)
      $$
      donc la série $\sum_{n \geq 2}\frac{1}{n^{\alpha}(\ln n)^{\beta}}$ diverge.
    - si $\alpha > 1$, soit $\gamma \in \oo{1,\alpha}$.
      $$
        n^{\gamma} \frac{1}{n^{\alpha}(\ln n)^{\beta}} = \frac{1}{n^{\alpha-\gamma}(\ln n)\beta} \arrowlim{n\to+\infty} 0
      $$
      donc
      $$
        0 \leq  \frac{1}{n^{\alpha}(\ln n)^{\beta}} = o \left(\frac{1}{n^{\gamma}}\right)
      $$
      et $\gamma > 1$ donc $\sum_{n \geq 2}\frac{1}{n^{\alpha}(\ln n)^{\beta}}$ converge.
    - si $\alpha = \beta = 1$, la série est $\sum_{n \geq 2} \frac{1}{n\ln n}$. Il existe donc pour $n \geq 2$, $c_{n} \in \oo{\ln n, \ln(n+1)}$.
      $$
        \ln \big(\ln(n+1)\big) - \ln \big(\ln n\big) = \frac{1}{c_{n}} \big(\ln(n+1) - \ln n\big)
      $$
      donc
      $$
        \ln n < c_{n} < \ln (n+1)
      $$
      donc $c_{n} \sim \ln n$ d’où
      $$
        \ln(n+1) - \ln n = \ln \left(1 + \frac{1}{n}\right) \sim \frac{1}{n}
      $$
      d’où
      $$
        \frac{1}{n\ln n} \sim \ln \big(\ln (n+1)\big) - \ln(\ln n)
      $$
      donc $\ln(\ln n) \arrowlim{n\to+\infty}+\infty$. Ainsi,
      $$
        \sum\ln \big(\ln(n+1)\big) - \ln(\ln n)
      $$
      diverge, donc $\sum \frac{1}{n\ln n}$ diverge.
    - Si $\alpha = 1$ et $\beta \ne 1$, considérons
      $$
        f: x \longmapsto  \frac{1}{(\ln x)^\gamma} = (\ln x)^{-\gamma}
      $$
      sa dérivée est
      $$
        f':x \longmapsto \frac{-\gamma}{x}(\ln x)^{-\gamma-1}
      $$
      Pour tout $n \geq 2$, il existe $c_{n} \in \oo{n, n+1}$ tel que
      $$
        f(n+1) - f(n) \oeq{TAF} (n+1-n)f'(c_{n}) = -\frac{\gamma}{n(\ln c_{n})^{\gamma + 1}}
      $$
      Donc
      $$
        \frac{1}{\big(\ln(n+1)\big)^{\gamma}} - \frac{1}{(\ln n)^{\gamma}} \usim{n\to+\infty} - \frac{\gamma}{n(\ln n)^{\gamma+1}}
      $$
      donc
      $$
        \underbrace{\frac{\beta-1}{n(\ln n)^{\beta}}}_{\geq 0} \sim \frac{1}{(\ln n)^{\beta-1}} - \frac{1}{\big(\ln(n+1)\big)^{\beta-1}}
      $$
      Comme $\beta-1 \ne 0$, les séries $\sum_{n \geq 2}\frac{1}{n(\ln n)^{\beta}}$ et $\sum_{n \geq 2} \frac{1}{\big((\ln(n+1))^{\beta-1}\big)} - \frac{1}{(\ln n)^{\beta-1}}$ ont la même nature. Or
      $$
        \frac{1}{(\ln n)^{\beta-1}} \arrowlim{} \begin{cases}0 & \text{si } \beta>1\\+\infty & \text{si } \beta<1\end{cases}
      $$
      donc $\sum \frac{1}{n(\ln n)^{\beta}}$ converge pour $\beta > 1$.
  %
%


## Règle d’Alembert

%thm
  Soit $\sum_{n \geq 0}a_{n}$ une série à termes réels strictement positifs. Supposons
  $$
    \frac{a_{n+1}}{a_{n}} \arrowlim{n\to+\infty}\ell \in \bar{\R_{+}}
  $$
  Alors
  - si $\ell > 1$ ou $\ell = 1^{+}$, alors $\sum_{n \geq 0}a_{n}$ est divergente grossièrement.
  - si $\ell \in  \co{0,1}$, alors $\sum_{n \geq 0}a_{n}$ est convergente.
  - sinon, on ne peut conclure directement.
%

%proof
  - Si $\ell > 1$ ou $\ell = 1^{+}$, il existe $N \in \N$ tel que $\forall n \geq N, \frac{a_{n+1}}{a_{n}}  \geq 1$. Alors
    $$
      \forall n \geq  N, a_{n+1}\geq a_{n} \geq a_{N}
    $$
    donc $(a_{n})_{n \geq N}$ est croissante et $a_{N} > 0$, d’où $(a_{n})$ ne tend pas vers 0: la série diverge grossièrement.
  - Supposons $\ell \in \co{0,1}$. Soit $q \in  \oo{\ell, 1}$.
    $$
      \exists N \in \N: \forall  n \geq N, 0 < \frac{a_{n+1}}{a_{n}} \leq q
    $$
    d’où
    $$
      \forall n \geq N, 0 \leq \prod_{k=N}^{n}\frac{a_{k+1}}{a_{k}} \leq q^{n-(N-1)}
    $$
    donc
    $$
      \forall  n \geq N, \frac{a_{n+1}}{a_{n}} \leq q^{n-(N-1)}
    $$
    Alors,
    $$
      \forall n \geq N, 0 \leq a_{n+1} \leq \frac{a_{N}}{q^{N-1}}q^{n}
    $$
    or $\sum_{n \geq 0}q^{n}$ converge car $0 \leq q < 1$, donc $\sum_{n \geq 0}a_{n}$ converge.
  - - Considérons la suite définie pour $n \in \N^{*}$ par $a_{n} = \frac{1}{n}$. Alors
      $$
        \frac{a_{n+1}}{a_{n}} = \frac{n}{n+1} \arrowlim{n\to+\infty}1^{-}
      $$
      et $\sum_{n \geq 1}a_{n}$ diverge.
    - La suite définie par $a_{n} = \frac{1}{n^{2}}$ vérifie
      $$
        \frac{a_{n+1}}{a_{n}} = \frac{n^{2}}{(n+1)^{2}} \arrowlim{n\to+\infty}1^{-}
      $$
      et $\sum_{n \geq 1} a_{n}$ converge.
%

%eg
  1. Soient $\alpha \in \R$ et $q \in \oo{0,1}$. Étudions la série $\sum_{n \geq 1}n^{\alpha}q^{n}$.
     - ++Première méthode++.
       $$
         n^{2} \times n^{\alpha}q^{n} = n^{\alpha+2}q^{n} \arrowlim{n\to+\infty}0
       $$
       donc $n^{\alpha}q^{n} = u \left(\frac{1}{n^{2}}\right)$, ainsi $\sum_{n \geq 1}n^{\alpha}q^{n}$ converge.
     - ++Deuxième méthode++. Soit $r \in \oo{q,1}$.
       $$
         n^{\alpha}\frac{q^{n}}{r^{n}} = n^{\alpha} \left(\frac{q}{r}\right)^{n} \arrowlim{n\to+\infty}0
       $$
       car $\frac{q}{n} < 1$. Qlors $n^{\alpha}q^{n} = o(r^{n})$ et $\sum r^{n}$ converge car $0 \leq r < 1$. Ainsi la série $\sum_{n \geq 1}n^{\alpha}q^{n}$ converge.
     - ++Troisième méthode++: régle de d’Alembert. Pour tout $n \geq 1$, $n^{\alpha}q^{n} > 0$ donc
       $$
         \frac{(n+1)^{\alpha}q{n+1}}{n^{\alpha}q^{n}} = \left(1+\frac{1}{n}\right)^{\alpha}q \arrowlim{n\to+\infty}q < 1
       $$
       donc $\sum_{n \geq 1}n^{\alpha}q^{n}$ est convergente.
  2. Nature de la série $\sum_{n \geq 1}\frac{2^{n} n!}{n^{n}}$.
     - ++Première méthode: formule de stirling++.
       %lemma Formule de Stirling
         $$
           n! \usim{n\to+\infty}\sqrt{2n \pi}\left(\frac{n}{e}\right)^{n}
         $$
       %
       On a
       $$
         \frac{2^{n}n!}{n^{n}} \usim{n\to+\infty}2^{n} \frac{\sqrt{2n \pi}}{n^{n}}\left(\frac{n}{e}\right)^{n}
       $$
       donc
       $$
         \frac{2^{n} n!}{n^{n}} \sim \sqrt{2 \pi} n^{1/2} \left(\frac{2}{e}\right)^{n}
       $$
       et $0 < \frac{2}{e} < 1$. Or $\sum_{n \geq 1}n^{1/2}\left(\frac{2}{e}\right)^{n}$ converge donc par comparaison de séries à termes positifs, $\sum_{n \geq 1}\frac{2^{n}n!}{n^{n}}$ est convergente.
    - ++Deuxième méthode: régle de d’Alembert++.
      $$
        \forall n \in \N^{*}, u_{n} = \frac{2^{n} n!}{n^{n}} > 0
      $$
      donc
      $$
        \begin{align*}
          \frac{u_{n+1}}{u_{n}} &= \frac{2^{n+1}(n+1)!}{(n+1)^{n+1}} \times \frac{n^{n}}{2^{n} n!}\\
          &= 2 \left(\frac{n}{n+1}\right)^{n}\\
          &=2 \left(\frac{n+1}{n}\right)^{-n}\\
          &= 2 \left(1+\frac{1}{n}\right)^{-n}\\
        \end{align*}
      $$
      donc $\frac{u_{n+1}}{u_{n}} \arrowlim{n\to+\infty}\frac{2}{e} < 1$, donc $\sum_{n \geq 1}u_{n}$ converge.
%

## Sommation de relations de comparaison

%prop
  Soit $(u_{n})_{n \in \N}$ une suite complexe. Soit $(a_{n})_{n \in \N}$ une suite réelle de signe constant à partir d’un certain rang.
  - si $\sum_{n \geq 0}a_{n}$((Série de référence de signe constant à partir d’un certain rang.)) converge.
    - Si $u_{n} = O(a_{n})$ (resp. $u_{n} = o(a_{n})$), alors $(u_{n})$ est sommable et
      $$
        \sum_{k=n}^{+\infty}u_{k} = O \left(\sum_{k=n}^{+\infty}a_{k}\right) \:\left( \text{resp. } o \left(\sum_{k=n}^{+\infty}a_{k}\right)\right)
      $$
    - Si $u_{n}\sim \lambda a_{n}$ pour $\lambda \in \C^{*}$, alors $(u_{n})_{n \in \N}$ est sommable et
      $$
        \sum_{k=n}^{+\infty}u_{k} \usim{n\to+\infty} \lambda \sum_{k=n}^{+\infty}a_{k}
      $$
  - si la série de référence diverge,
    - si $u_{n} = O(a_{n})$ (resp. $u_{n} = o(a_{n})$), alors on ne peut rien dire sur la nature de $\sum u_{n}$. Par contre, on a
      $$
        \sum_{k=0}^{n}u_{k} \ueq{n\to+\infty} O \left(\sum_{k=0}^{n}a_{k}\right) \: \left(\text{resp. }o \left(\sum_{k=0}^{n}a_{k}\right)\right)
      $$
    - si $a_{n} \sim \lambda a_{n}$ pour $\lambda \in \C^{*}$, alors $\sum_{n \geq 0}u_{n}$ diverge et
      $$
        \sum_{k=0}^{n}u_{k} \sim \lambda \sum_{k=0}^{n}a_{k}
      $$
%

%proof
  - Si $(a_{n})$ est de signe constant à partir d’un certain rang, $u_{n} = O(a_{n})$ et $\sum a_{n}$ **converge**, alors
    $$
      \exists M \in \R_{+}: \exists n_{0} \in \N: \begin{cases}\forall n \geq n_{0}, \abs{u_{n}}\leq M \abs{a_{n}}\\ (a_{n})_{n \geq  n_{0}} \text{ est de signe constant}\end{cases}
    $$
    donc $\sum_{n \geq 0}\abs{u_{n}}$ converge car $\forall n \geq n_{0}, \abs{a_{n}} = a_{n}$ ou $\forall n \geq n_{0}, \abs{a_{n}} = -a_{n}$, donc $\sum_{n \geq 0}u_{n}$ converge, et pour $n \geq n_{0}$,
    $$
      \abs{\sum_{k=n}^{+\infty}u_{k}} \leq  \sum_{k=n}^{+\infty}\abs{u_{k}} \leq M \sum_{k=n}^{+\infty}\abs{a_{k}} = M \abs{\sum_{k=n}^{+\infty}a_{k}}
    $$
  - Supposons $u_{n} \sim \lambda a_{n}$ pour $\lambda \in \C^{*}$. Alors $\abs{a_{n}} \sim \abs{\lambda} \abs{a_{n}}$ donc $\sum_{n \geq 0} \abs{a_{n}}$ converge.
    $$
      \frac{u_{n}}{\lambda} \sim a_{n} \quad\text{i.e.}\quad \frac{u_{n}}{\lambda}\sim a_{n} + o(a_{n})
    $$
    i.e. $\frac{u_{n}}{\lambda} - a_{n} = o(a_{n})$. Ainsi
    $$
      \sum_{k=n}^{+\infty}\left(\frac{u_{k}}{\lambda}-a_{k}\right) = o \left( \sum_{k=n}^{+\infty}a_{k}\right)
    $$
    i.e.
    $$
      \frac{1}{\lambda}\sum_{k=n}^{+\infty}u_{k} - \sum_{k=n}^{+\infty}a_{k} = o \left(\sum_{k=n}^{+\infty}a_{k}\right)
    $$
    donc
    $$
      \frac{1}{\lambda}\sum_{k=n}^{+\infty}u_{k} \usim{n\to+\infty} \sum_{k=n}^{+\infty}a_{k}
    $$
  - Si $(a_{n})$ est de signe constant à partir d’un certain rang, $u_{n} = O(a_{n})$ et $\sum a_{n}$ **diverge**, alors
    $$
      \exists M \in \R_{+}: \exists n_{0} \in \N: \begin{cases}\forall n \geq n_{0}, \abs{u_{n}}\leq M \abs{a_{n}}\\ (a_{n})_{n \geq  n_{0}} \text{ est de signe constant}\end{cases}
    $$
    donc pour $n \geq n_{0}$,
    $$
      \abs{\sum_{k=n}^{+\infty}u_{k}} \leq  \sum_{k=n}^{+\infty}\abs{u_{k}} \leq M \sum_{k=n}^{+\infty}\abs{a_{k}} = M \abs{\sum_{k=n}^{+\infty}a_{k}}
    $$
    d’où
    $$
      \forall  n \geq n_{0}, \abs{\sum_{k=n_{0}}^{n}u_{k}} \leq M \abs{\sum_{k=0}^{n}a_{k}  \sum_{k=0}^{n_{0}-1}a_{k}} \leq M \left(\abs{\sum_{k=0}^{n}a_{k}} + \abs{\sum_{k=0}^{n_{0}-1}}\right)
    $$
    or $\abs{\sum_{k=0}^{n}a_{k}} \arrowlim{n\to+\infty}+\infty$. Ainsi, il existe $n_{1} \geq n_{0}$ tel que
    $$
      \forall n \geq n_{1}, \abs{\sum_{k=0}^{n_{0}-1}a_{k}} \leq M \abs{\sum_{k=0}^{n}a_{k}}
    $$
    et
    $$
      \abs{\sum_{k=0}^{n_{0}-1}u_{k}} \leq \abs{\sum_{k=0}^{n}a_{k}}
    $$
    d’où
    $$
      \forall n \geq n_{1}, \abs{\sum_{k=0}^{n}u_{k}} \leq  \abs{\sum_{k=0}^{n_{0}-1}u_{k}} + 2M \abs{\sum_{k=0}^{n}a_{k}} \leq 3M \abs{\sum_{k=0}^{n}u_{k}}
    $$
    - $\frac{1}{n} = O \left(\frac{1}{n}\right)$, $\frac{1}{n^{2}} = O \left(\frac{1}{n}\right)$ et $\sum \frac{1}{n}$ diverge, pourtant $\sum \frac{1}{n}$ diverge alors que $\sum \frac{1}{n^{2}}$ converge.
  - si $u_{n} \usim{n\to+\infty} \lambda a_{n}$, alors $\frac{u_{n}}{\lambda} - a_{n} = o(a_{n})$ donc $\sum_{k=0}^{n}\frac{u_{k}}{\lambda} - \sum_{k=0}^{n}a_{k} = o \left(\sum_{k=0}^{n}a_{k}\right)$. D’où
    $$
      \sum_{k=0}^{n}\frac{u_{k}}{\lambda} \sim \sum_{k=0}^{n}a_{k}
    $$
    donc
    $$
      \sum_{k=0}^{n}u_{k}\usim{n\to+\infty} \lambda \sum_{k=0}^{n}a_{k}
    $$
    D’où
    $$
      \abs{\sum_{k=0}^{n}u_{k}} \usim{n\to +\infty}\abs{\lambda} \abs{\sum_{k=0}^{n}a_{k}} \arrowlim{n\to+\infty}+\infty
    $$
    Nécessairement, $\sum_{k \geq 0} u_{k}$ est divergente.
%

%eg
  1. $\sum_{k \geq 1}\frac{1}{k^{2}}$ est convergente.
     $$
       \frac{1}{k^{2}} \usim{k\to+\infty} \frac{1}{k(k+1)}
     $$
     $\sum \frac{1}{k^{2}}$ est une série convergente à termes positifs, donc
     $$
       \sum_{k=n}^{+\infty}\frac{1}{k^{2}} \sim \sum_{k=n}^{+\infty}\frac{1}{k(k+1)} = \sum_{k=n}^{+\infty} \left(\frac{1}{k} - \frac{1}{k+1}\right)
     $$
     Or
     $$
       \sum_{k=n}^{N}\left(\frac{1}{k} - \frac{1}{k+1}\right) = \frac{1}{n} - \frac{1}{N+1} \arrowlim{N \to+\infty} \frac{1}{n}
     $$
     donc
     $$
       \boxed{\sum_{k=n}^{+\infty}\frac{1}{k^{2}}\usim{n\to+\infty}\frac{1}{n}}
     $$
  2. $\sum_{n \geq 1}\frac{1}{k^{3}}$ est convergente.
     $$
       0 < \frac{1}{k^{3}} \usim{k\to+\infty} \frac{1}{k(k+1)(k+2)}
     $$
     donc
     $$
       \sum_{k=n}^{+\infty}\frac{1}{k^{3}}\sim \sum_{k=n}^{+\infty}\frac{1}{k(k+1)(k+2)}
     $$
     On effectue la décomposition en éléments simples :
     $$
       \frac{1}{X(X+1)(X+2)} = \frac{1/2}{X} - \frac{1}{X+1} + \frac{1/2}{X+2}
     $$
     On a alors
     $$
       \sum_{k=n}^{+\infty}\frac{1}{k^{3}} \sim \frac{1}{2} \left(\sum_{k=n}^{+\infty}\frac{1}{k} - \frac{2}{k+1} + \frac{1}{k+2}\right)
     $$
     Or
     $$
       \sum_{k=n}^{N} \left(\frac{1}{k} - \frac{1}{k+1}\right) + \sum_{k=n}^{N}\frac{1}{k+2} - \frac{1}{k+1} = \frac{1}{n} - \frac{1}{N+1} + \frac{1}{N+2} - \frac{1}{n+1} \arrowlim{N\to+\infty} \frac{1}{n} - \frac{1}{n+1} = \frac{1}{n(n+1)}
     $$
     donc
     $$
       \sum_{k=n}^{+\infty}\frac{1}{k^{3}} \sim \frac{1}{2n(n+1)} \sim \frac{1}{2n^{2}}
     $$
%

%thm Théorème de Cesaro
  - Soit $(u_{n})_{n \in \N}$ une suite complexe. Si $u_{n} \arrowlim{n\to+\infty}\ell \in \C$, alors
    $$
      \frac{u_{1} + \cdots + u_{n}}{n} \arrowlim{n\to+\infty}\ell
    $$
  - Si $(u_{n})_{n \in \N}$ est une suite réelle telle que $u_{n} \arrowlim{n\to+\infty} \varepsilon \infty$ avec $\varepsilon = \pm 1$, alors
    $$
      \frac{u_{1} + \cdots + u_{n}}{n} \arrowlim{n\to+\infty} \varepsilon \infty
    $$
%

%proof
  - - Supposons $\ell \in \C^{*}$. $u_{n} \sim \ell = \ell \cdot 1$, et $\sum_{n \geq 0}1$ est une série divergente de signe constant, donc
      $$
        \sum_{k=1}^{n}u_{k} \usim{n\to+\infty} \ell \cdot  \sum_{k=1}^{n}1
      $$
      d’où $u_{1} + \cdots + u_{n} \usim{n\to+\infty} n\ell$ donc
      $$
        \frac{u_{1} + \cdots + u_{n}}{n} \usim{n\to+\infty} \ell
      $$
    - si $\ell = 0$, $u_{n} = o(1)$ et $\sum_{n \geq 0}1$ est une série divergente à termes positifs, donc
      $$
        \sum_{k=1}^{n} u_{k} \ueq{n\to+\infty} O \left(\sum_{k=1}^{n}1\right) = o(n)
      $$
      donc
      $$
        \frac{u_{1} + \cdots + u_{n}}{n} = o(1)
      $$
  - Soit $(u_{n})_{n \in \N}$ une suite réelle divengente. Alors,
    $$
      \exists  n_{0} \in \N: \forall n \geq n_{0}, u_{n} > 0
    $$
    donc $\frac{1}{u_{n}} \arrowlim{n\to+\infty}0^{+}$ donc
    $$
      \frac{\frac{1}{u_{n_{0}}} + \cdots + \frac{1}{u_{n}}}{n-(n_{0}-1)} \arrowlim 0^{+}
    $$
    Or
    $$
      0 \leq  \sqrt[n-(n_{0}-1)]{\frac{1}{u_{n_{0}}} \times \cdots \times  \frac{1}{u_{n}}} \overset{\text{IAG}}\leq \frac{\frac{1}{u_{n_{0}}} + \cdots + \frac{1}{u_{n}}}{n-(n_{0}-1)}
    $$
    donc
    $$
      \underbrace{\frac{n(n_{0}-1)}{\frac{1}{u_{n_{0}}} + \cdots + \frac{1}{u_{n}}}}_{\arrowlim{}+\infty} \leq  \sqrt[n-(n_{0}-1)]{u_{n_{0}} \times  \cdots \times  u_{n}} \underset{\text{IAG}}\leq  \underbrace{\frac{u_{n_{0}} + \cdots + u_{n}}{n-(n_{0}-1)}}_{\coloneqq q_{n}}
    $$
    d’où
    $$
      \frac{u_{1} + \cdots + u_{n}}{n} = \frac{u_{1} + \cdots + u_{n_{0}-1}}{n} + q_{n} \times \frac{n - (n_{0}-1)}{n} \arrowlim{n\to+\infty}0 + (+\infty) \times 1
    $$
%

%rem
  Si sur un parcours, l’aller se fait à la vitesse $v_{A}$ et le retour à la vitesse $v_{B}$, alors la vitesse moyenne sur le parcours est la **moyenne harmonique** des vitesses. En effet,
  $$
    v = \frac{2d}{t_{A} + t_{B}} = \frac{2d}{\frac{d}{v_{A}} + \frac{d}{v_{B}}} = \frac{2}{\frac{1}{v_{A}} + \frac{1}{v_{B}}}
  $$
%

%offprog
  ## Transformations d’Abel

  1. ++Première transformation d’Abel.++
     Soient $(a_{n})_{n \in \N}$ et $(b_{n})_{n \in \N}$ deux suites complexes. Le but est d’étudier $\sum_{k=n}^{p}a_{k}b_{k}$. On pose, pour $n \in \N$,
     $$
       B_{n} = \sum_{k=0}^{n}b_{k} \quad\text{et}\quad B_{-1} = 0
     $$
     Alors
     $$
       \forall k \in \N, b_{k} = B_{k} - B_{k-1}
     $$
     d’où
     $$
       \begin{align*}
         \sum_{k=n}^{p}a_{k}b_{k} &= \sum_{k=n}^{p}a_{k}(B_{k} - B_{k-1})\\
         &= \sum_{k=n}^{p}a_{k}B_{k} - \sum_{k=n}^{p}a_{k}B_{k-1}\\
         &= \sum_{k=n}^{p}a_{k}B_{k} - \sum_{k=n-1}^{p-1}a_{k-1}B_{k}\\
         &= a_{p}B_{p} - a_{n} B_{n-1} - \sum_{k=n}^{p-1}(a_{k-1}-a_{k})B_{k}
       \end{align*}
     $$
     pour $n < p$.
     %rem
       Il s’agit d’une intégration par parties discrète.
     %
  2. ++Deuxième transformation d’Abel++. Supposons $\sum_{n \geq 0}b_{n}$ convergente. On pose pour $n \in \N \cup \{-1\}$,
     $$
       R_{n} = \sum_{k=n+1}^{+\infty}b_{k}
     $$
     On a alors $\forall k \in \N, b_{k} = R_{k-1} - R_{k}$, d’où
     $$
       \begin{align*}
         \sum_{k=n}^{p}a_{k}b_{k} &= \sum_{k=n}^{p}a_{k}(R_{k-1}-R_{k})\\
         &= \sum_{k=n}^{p}a_{k} R_{k-1} - \sum_{k=n}^{p}a_{k} R_{k}\\
         &= \sum_{k=n-1}^{p-1}a_{k+1}R_{k} - \sum_{k=n}^{p}a_{k} R_{k}\\
         &= a_{n} R_{n-1} - a_{p}R_{p} + \sum_{k=n}^{p-1}(a_{k+1} - a_{k}) R_{k}
       \end{align*}
     $$
%

%eg
  Donner un équivalent *simple* de $S_{n} = \sum_{k=1}^{k}2^{k}\ln(k)$. On réalise une transformation d’Abel : posons pour $n \in \N$ la suite définie par $U_{-1} = 0$ et
  $$
    U_{n} = \sum_{k=0}^{n}2^{k} = \frac{1-2^{n+1}}{1-2} = 2^{n+1}-1
  $$
  Alors
  $$
    \begin{align*}
      \sum_{k=1}^{n}2^{k}\ln k &= \sum_{k=1}^{n}(U_{k} - U_{k-1})\ln k\\
      &= \sum_{k=1}^{n}U_{k}\ln k - \sum_{k=1}^{n}U_{k-1}\ln k\\
      &= \sum_{k=1}^{n}U_{k}\ln k - \sum_{k=0}^{n-1}U_{k}\ln(k+1)\\
      &= U_{n}\ln n - U_{0}\ln 1 - \sum_{k=1}^{n-1}U_{k}(\ln(k+1) - \ln k)\\
      &= (2^{n+1}-1)\ln n - \sum_{k=1}^{n-1}(2^{k+1}-1)\ln \left(1 + \frac{1}{k}\right)
    \end{align*}
  $$
  or la série $\sum_{k \geq 1}2^{k}\ln k$ diverge, $2^{k}\ln k \geq 0$ pour $k \in \N^{*}$ et
  $$
    (2^{k+1}-1)\ln \left(1 + \frac{1}{k}\right) \ueq{k\to+\infty} o(2^{k}\ln k)
  $$
  donc
  $$
    \sum_{k=1}^{n-1}(2^{k+1}-1)\ln \left(1+\frac{1}{k}\right) \ueq{n\to+\infty} \left(\sum_{k=1}^{n-1}2^{k}\ln k\right)
  $$
  d’où
  $$
    S_{n-1} + 2^{n}\ln n \ueq{k\to+\infty} (2^{n+1}-1)\ln n + o(S_{n-1})
  $$
  d’où
  $$
    S_{n-1} \ueq{n\to+\infty} (2^{n+1} - 2^{n} - 1)\ln n + o(S_{n-1}) \ueq{n\to+\infty} (2^{n} - 1)\ln n + o(S_{n-1})
  $$
  d’où
  $$
    S_{n-1} \usim{n\to+\infty} (2^{n} - 1)\ln n \usim{n\to+\infty} 2^{n}\ln n
  $$
  donc $S_{n} \usim{n\to+\infty} 2^{n+1}\ln(n+1)$. Ainsi, $S_{n} \usim{n\to+\infty} 2^{n+1}\ln n$.
%

%offprog
  %prop Règle d’Abel
    Soit $(\varepsilon_{n})_{n \in \N}$ une suite réelle décroissante tendant vers 0. Soit $(z_{n})_{n \in \N}$ une suite à valeurs dans un **espace vectoriel normé complet** vérifiant
    $$
      \exists M \in \R_{+}: \forall n \in \N, \norm{\sum_{k=0}^{n}z_{k}} \leq M
    $$
    %rem
      Cela n’assure en rien la convergence de $\sum_{k \geq 0}z_{k}$.
    %
    Alors $\sum_{n \geq 0}\varepsilon_{n}z_{n}$ est convergente et
    $$
      \forall n \in \N, \abs{\sum_{k=n+1}^{+\infty}\varepsilon_{k}z_{k}} \leq 2M \varepsilon_{n+1}
    $$
  %

  %proof
    Posons pour $n \in \N$
    $$
      Z_{-1} = 0 \quad\text{et}\quad Z_{n} = \sum_{k=0}^{n}z_{k}
    $$
    Soit $n \in \N^{*}$.
    $$
      \begin{align*}
        \sum_{k=0}^{n}\varepsilon_{k}z_{k} &= \sum_{k=0}^{n}\varepsilon_{k}(Z_{k} - Z_{k-1})\\
        &= \sum_{k=0}^{n}\varepsilon_{k}Z_{k} - \sum_{k=-1}^{n-1}\varepsilon_{k+1}Z_{k}\\
        &= \varepsilon_{n}Z_{n} - \varepsilon_{0} Z_{-1} - \sum_{k=0}^{n-1}(\varepsilon_{k+1} - \varepsilon_{k})Z_{k}\\
        &= \varepsilon_{n}Z_{n} - \sum_{k=0}^{n-1}(\varepsilon_{k+1} - \varepsilon_{k})Z_{k}
      \end{align*}
    $$
    or
    - $\forall n \in \N^{*}, \norm{\varepsilon_{n}Z_{n}} \leq M \arrowlim{n\to+\infty}0$ donc $\varepsilon_{n}Z_{n} \arrowlim{n\to+\infty}0_{\C}$
    - $\norm{(\varepsilon_{k+1} - \varepsilon_{k})Z_{k}} \leq  M(\varepsilon_{k} - \varepsilon_{k+1})$ et ce majorant est terme général d’une série téléscopique convergente car $(\varepsilon_{k})_{k \in \N}$ converge.
    ainsi, $\sum_{k \geq 0}(\varepsilon_{k+1} - \varepsilon_{k})Z_{n}$ est absolument convergente donc convergente ($E$ est complet). Alors
    $$
      \sum_{k=0}^{n}\varepsilon_{k} z_{k} \arrowlim{n\to+\infty} 0 - \sum_{k=0}^{+\infty}(\varepsilon_{k+1} - \varepsilon_{k})Z_{k} \in E
    $$
    donc $\sum_{k \geq 0}\varepsilon_{k} z_{k}$ est convergente et
    $$
      \sum_{k=0}^{+\infty}\varepsilon_{k} z_{k} = \sum_{k=0}^{+\infty}(\varepsilon_{k} - \varepsilon_{k+1})Z_{k}
    $$
    Soit $p \geq n+1$.
    $$
      \sum_{k=n+1}^{p}\varepsilon_{k} z_{k} = \varepsilon_{p}Z_{p} - \varepsilon_{n+1}Z_{n} - \sum_{k=n+1}^{p-1}(\varepsilon_{k+1}-\varepsilon_{k})Z_{k}
    $$
    On fait tendre $p$ vers $+\infty$ :
    $$
      \sum_{k=n+1}^{+\infty}\varepsilon_{k}z_{k} = -\varepsilon_{n+1}Z_{n+1} + \sum_{k=n+1}^{+\infty}(\varepsilon_{k} - \varepsilon_{k+1})Z_{k}
    $$
    d’où, par absolue convergence de $\sum_{(\varepsilon_{k+1} - \varepsilon_{k})Z_{n}}$,
    $$
      \abs{\sum_{k=n+1}^{+\infty}\varepsilon_{k} z_{k}} \leq  \varepsilon_{n+1} M + \sum_{k=n+1}^{+\infty}(\varepsilon_{k} - \varepsilon_{k+1})M
    $$
    Or
    $$
      \sum_{k=n+1}^{+\infty}(\varepsilon_{k} - \varepsilon_{k+1})M = M \lim_{N\to+\infty} \left(\sum_{k=n+1}^{+\infty}(\varepsilon_{k} - \varepsilon_{k+1})\right) = M\lim_{N\to+\infty}(\varepsilon_{n+1} - \varepsilon_{N+1}) = M \varepsilon_{n+1}
    $$
    d’où
    $$
      \abs{\sum_{k=n+1}^{+\infty}\varepsilon_{k} z_{k}} \leq  2M \varepsilon_{n+1}
    $$
  %
%

%rem
  Soit $(\varepsilon_{n})_{n \in \N}$ une suite décroissante tendant vers 0. La suite $(z_{n})$ définie pour $n \in \N$ par $z_{n} = (-1)^{n}$ vérifie
  $$
    \forall n \in \N, \abs{\sum_{k=0}^{n}z_{k}} \leq 1
  $$
  donc d’après la règle d’Abel, les séries $\sum_{n \geq 0}(-1)^{n} \varepsilon_{n}$ et $\sum_{n \geq 0}(-1)^{n+1}\varepsilon_{n}$ convergent: on retrouve le résultat du théorème des séries alternées.
  Cependant, ce théorème donne une meilleure majoration du reste :
  $$
    \forall n \in \N, \abs{\sum_{k=n+1}^{+\infty}(-1)^{k} \varepsilon_{k}} \leq \varepsilon_{n+1}
  $$
%

%eg
  Étudions la nature de la série $\sum_{n \geq 1}\frac{e^{in \theta}}{n^{\alpha}}$ avec $(\theta, \alpha) \in \R^{2}$.
  - Si $\alpha \leq 0$.
    $$
      \abs{\frac{e^{in \theta}}{n^{\alpha}}} = n^{-\alpha} \arrowlim{n\to+\infty} \begin{cases}+\infty & \text{si } \alpha<0\\ 1 & \text{si } \alpha=0\end{cases}
    $$
    donc $\left(\frac{e^{in \theta}}{n^{\alpha}}\right)_{n \in \N}$ ne tend pas vers 0: on a divergence grossière de la série.
  - Si $\alpha > 1$.
    $$
      \forall n \in \N^{*}, \abs{\frac{e^{in \theta}}{n^{\alpha}}} = \frac{1}{n^{\alpha}}
    $$
    or $\sum_{n \geq 1}\frac{1}{n^{\alpha}}$ converge ($\alpha > 1$) donc $\sum_{n \geq 1} \frac{e^{in \theta}}{n^{\alpha}}$ converge absolument. Étant à valeurs complexes, celle-ci converge.

  %offprog
    - si $\alpha \in \oc{0,1}$, la série $\sum_{n \geq 1}\frac{e^{in \theta}}{n^{\alpha}}$ ne converge pas absolument. $\left(\frac{1}{n^{\alpha}}\right)_{n \in \N^{*}}$ est une suite décroissante tendant vers 0. Pour $e^{i \theta}\ne 1$,
      $$
        \sum_{k=1}^{n}e^{ik \theta} = \sum_{k=1}^{n}(e^{i \theta})^{k} = e^{i \theta} \frac{1 - (e^{i \theta})^{n}}{1 - e^{i \theta}}
      $$
      donc pour $\theta \notin 2 \pi\Z$,
      $$
        \sum_{k=1}^{n}e^{ik \theta} = e^{i \theta} \frac{-2i \sin \left(\frac{n \theta}{2}\right)}{-2i \sin \left(\frac{\theta}{2}\right)}
      $$
      Ainsi,
      $$
        \forall  \theta \notin 2 \pi \Z, \forall n \in \N^{*}, \abs{\sum_{k=1}^{n}e^{ik \theta}} \leq \frac{1}{\abs{\sin \frac{\theta}{2}}}
      $$
      On peut donc appliquer la règle d’Abel: la série $\sum_{n \geq 1}\frac{e^{in \theta}}{n^{\alpha}}$ converge pour $\theta \notin 2 \pi\Z$ et si $\theta \in 2 \pi\Z$, la série $\sum_{n \geq 1}\frac{e^{in \theta}}{n^{\alpha}} = \sum_{n \geq 1}\frac{1}{n^{\alpha}}$ diverge pour $\alpha \in \oc{0,1}$.
  %
  On a donc finalement
  $$
    \sum_{n \geq 1}\frac{e^{in \theta}}{n^{\alpha}} \text{convergente} \iff \begin{cases}\alpha > 0\\ \theta \notin 2 \pi\Z\end{cases} \text{ ou } \alpha > 1
  $$
%
