# Tribus et probabilités sur un univers fini ou infini

:date 03/02/2026

On admet l’axiome du choix dans sa forme la plus générale.

- ++Expérience aléatoire n°1~:++ On lance une pièce (pile: 0 / face: 1) jusqu’à obtenir face. L’univers est
  $$
    \Omega_{1} = \{(0)_{n \in \N^{*}}\} \cup \{(1)\} \cup \bigcup_{n \in \N^{*}}\{0\}^{n} \times \{1\}
  $$
  c’est l’ensemble des résultats ou « issues » possibles. Il est ici dénombrable.
- ++Expérience aléatoire n°2~:++ On lance une pièce de façon infinie. L’univers est $\Omega_{2} = \{0,1\}^{\N^{*}}$. On a $\Omega_{2} \approx \Part(\N^{*}) \approx \R$ donc $\Omega_{2}$ n’est pas dénombrable. On définit l’événement $A_{n}$: « ne pas obtenir face avant le n-ième lancer » soit $A_{n} = \{0\}^{n-1} \times  \{0,1\}^{\ico{n,+\infty}} \in \Part(\Omega_{2})$.

## Tribus

%def Axiomatique de Kolmogorov
  Soit $\Omega$ un ensemble. Une partie $\Tribu$ de $\Part(\Omega)$ de $\Part(\Omega)$ est appelée _tribu_ sur $\Omega$ (ou $\sigma$-algèbre) si~:
  - $\Omega \in \Tribu$
  - $\forall A \in \Tribu, A^{\complement} = \bar{A} \in A$
  - Si $(A_{n})_{n \in \N}$ est une suite de parties de $\Tribu$, alors $\bigcup_{n \in \N} A_{n} \in \Tribu$.
  On dit que $(\Omega, \Tribu)$ est un _espace probabilisable_.
%

%eg
  1. $\Part(\Omega)$ est une tribu sur $\Omega$ appelée _tribu discrète_ sur $\Omega$. C’est celle que l’on considére systématiquement si $\Omega$ est au plus dénombrable. On ne la considère jamais si $\Omega$ n’est pas au plus dénombrable.
  2. $\{\emptyset, \Omega\}$ est une tribu sur $\Omega$ appelée _tribu grossière_ et est rarement considérée.
  3. Soit $f: \Omega \longrightarrow \Omega'$ une application entre deux ensembles. Soit $A'$ une tribu sur $\Omega$. Posons $A = \big\{f^{-1}(A') \where A' \in \Tribu\big\}$.
     - Comme $\Omega' \in \Tribu$ et $f^{-1}(\Omega') \in \Omega$, on a $\Omega \in \Tribu$.
     - Soit $A \in \Tribu$. Il existe $A' \in \Tribu$ tel que $A = f^{-1}(A')$. Alors, $A^{\complement} = f^{-1}(A'^{\complement})$ or $A'$ est une tribu donc $A'^{\complement} \in \Tribu'$ d’où $A^{\complement} \in \Tribu$.
     - Soit $(A_{n})_{n \in \N}$ une suite d’éléments de $\Tribu$. Il existe alors une suite $(A_{n}')_{n \in \N}$ d’éléments de $\Tribu'$ telle que $\forall n \in \N, A_{n} = f^{-1}(A'_{n})$ d’où
       $$
         \bigcup_{n \in \N}A_{n} = f^{-1} \left(\bigcup_{n \in \N} A'_{n}\right)
       $$
       or $\Tribu'$ est une tribu donc $\bigcup_{n \in \N}A'_{n} \in \Tribu'$ donc $\bigcup_{n \in \N} A_{n} \in \Tribu$.
     $\Tribu$ est donc une tribu sur $\Omega$.
%

%property
  Soit $(\Omega, \Tribu)$ un espace probabilisable. On a
  - $\emptyset \in \Tribu$
  - $\Tribu$ est stable par intersection dénombrable
  - $\Tribu$ est stable par réunion et intersection finie
  - $\Tribu$ est stable par différence et différence symétrique
  %offprog
    - $\Tribu$ est stable par limite inférieure et supérieure
  %
%

%proof
  - $\Omega \in \Tribu$ et $\Tribu$ est stable par passage au complémentaire donc $\Omega^{\complement} = \emptyset  \in \Tribu$.
  - Soit $(A_{n})_{n \in \N}$ une suite d’éléments de $\Tribu$. Comme $\Tribu$ est une tribu, on a $\forall n \in \N, A_{n}^{\complement} \in \Tribu$ et $\bigcup_{n \in \N} \left(A_{n}^{\complement}\right) \in \Tribu$ donc $\left(\bigcup_{n \in \N} \big(A_{n}^{\complement}\big)\right)^{\complement} \in \Tribu$ i.e. $\bigcap_{n \in \N} A_{n} \in \Tribu$.
  - Soit $n \in \N^{*}$. Soit $(A_{1}, \ldots, A_{n}) \in \Tribu^{n}$. Posons, pour $k \geq n+1$, $A_{k} = \emptyset \in \Tribu$. On a alors $\bigcup_{k \in \N^{*}}A_{k} \in \Tribu$ i.e. $\bigcup_{k \in \icc{1,n}} A_{k} \in \Tribu$. En prenant pour $k \geq n+1$, $A_{k} = \Omega$, on a
    $$
      \bigcap_{k \in \N^{*}} A_{k} = \bigcap_{k \in \icc{1,n}}A_{k} \in \Tribu
    $$
  - Soit $(A,B) \in \Tribu^{2}$.
    ~ $A \setminus B = A \cap B^{\complement} \in \Tribu$  ~ $A \sym B = (A \setminus B) \cup (B \setminus A) \in \Tribu$
  %offprog
    - Soit $(A_{n})_{n \in \N}$ une suite d’éléments de $\Tribu$. On pose
      - $\limsup_{n \in \N} A_{n} \defeq \bigcap_{n \in \N} \bigcup_{k \geq n} A_{k} \in \Tribu$
      - $\liminf_{n \in \N} A_{n} \defeq \bigcup_{n \in \N} \bigcap_{k \geq n} A_{k} \in \Tribu$
      et on a
      $$
        \omega \in \limsup_{n \in \N}A_{n} \iff \forall n \in \N, \exists k \geq n: \omega \in A_{k}
      $$
      soit $\limsup_{n \in \N}A_{n}$: « appartenir à une infinité de $A_{n}$ » et
      $$
        \omega \in \liminf_{n \in \N}A_{n} \iff \exists n \in \N, \exists k \geq n: \omega \in A_{k}
      $$
      soit $\limsup_{n \in \N}A_{n}$: « appartenir à tous les $A_{n}$ à partir d’un certain rang ».
  %
%

%def
  Soit $(\Omega, \Tribu)$ un espace probabilisable.
  - On appelle _événement_ tout élément de $\Tribu$
  - $\emptyset$ est l’_événement impossible_ et $\Omega$ est l’_événement certain_.
  - Si $(\Omega_{i})_{i \in I}$ est une « partition »((pouvant contenir l’ensemble vide contrairement à une partition ensembliste.)) de $\Omega$ avec $\forall i \in I, \Omega_{i} \in \Tribu$, alors $(\Omega_{i})_{i \in I}$ est appelé _système complet d’événements_.
  - Pour $\omega \in \Omega$, on peut ne pas avoir $\{\omega\} \in \Tribu$. Si $\{\omega\} \in \Tribu$, alors $\{\omega\}$ est appelé _événement élémentaire_.
%

%offprog
  %prop
    Toute intersection de tribus sur $\Omega$ est une tribu sur $\Omega$.
  %

  %proof
    Soit $(\Tribu_{i})_{i \in I}$ une famille de tribus sur $\Omega$ indexée par un ensemble quelconque $I$. ($\bigcap_{i \in \emptyset} \Tribu_{i} = \Part(\Omega)$ est bien une tribu sur $\Omega$).
    - $\forall i \in I, \Omega \in \Tribu_{i}$ donc $\Omega \in \bigcap_{i \in I}\Tribu_{i}$
    - Soit $A \in \bigcap_{i \in I} \Tribu_{i}$. On a $\forall i \in I, A \in \Tribu_{i}$. Chaque $\Tribu_{i}$ est une tribu sur $\Omega$ donc $\forall i \in I, A^{\complement} \in \Tribu_{i}$ d’où $A^{\complement} \in \bigcap_{i \in I}\Tribu_{i}$.
    - Soit $(A_{n})_{n \in \N}$ une suite d’éléments de $\bigcap_{i \in I}\Tribu_{i}$. On a $\forall i \in I, \forall n \in \N, A_{n} \in \Tribu_{i}$ donc $\forall i \in I, \bigcup_{n \in \N}A_{n} \in \Tribu_{i}$ d’où $\bigcup_{n \in \N}A_{n} \in \bigcap_{i \in I}\Tribu_{i}$.
  %

  %def
    Soit $\Omega$ un ensemble. Soit $\G$ une partie de $\Part(\Omega)$. On pose
    $$
      \sigma(\G) = \bigcap_{\substack{\Tribu \text{ tribu sur } \Omega\\ \G \subset \Tribu}}\Tribu
    $$
    C’est la plus petite tribu (au sens de l’inclusion) sur $\Omega$ contenant $\G$: c’est la _tribu engendrée_ par $\G$.
  %

  %eg
    Soit $\Omega$ un ensemble.
    - $\sigma(\{\emptyset\}) = \{\emptyset, \Omega\}$
    - Soit $A \in \Part(\Omega)$. $\sigma(\{A\}) = \{\emptyset, A, A^{\complement}, \Omega\}$.
    - Soit $(A,B) \in \Part(\Omega)^{2}$.
      $$
        \sigma(\{A,B\}) = \left\{\bigcup_{D \in I} D \where I \subset \{A \setminus B, B \setminus A, A \cap B, (A \cap B)^{\complement}\}\right\}
      $$
    - Soit $(E, \norm{\cdot})$ un $\K$-espace vectoriel normé non nul. Notons $\T$ la topologie de $E$, i.e. l’ensemble des ouverts de $E$. Elle n’est pas stable par passage au complémentaire. $\sigma(\T) = \B(E)$ est la _tribu des boréliens_.
      - $\B(E) \supset F_{\sigma}$ (union dénombrable de fermés)
      - $\B(E) \supset G_{\delta}$ (intersection dénombrable d’ouverts)
    Par exemple,
    $$
      \co{0,1} = \bigcap_{n \in \N^{*}} \oo{- \frac{1}{n}, 1} \in G_{\delta}
    $$
    et
    $$
      \co{0,1} \in \bigcup_{n \in \N^{*}} \cc{0, 1-\frac{1}{n}} \in F_{\sigma}
    $$
  %
%

## Probabilité

%def Espace probabilisé, (loi de) probabilité
  On appelle espace probabilisé tout triplet $(\Omega, \Tribu, \P)$ où $\Tribu$ est une tribu sur un ensemble $\Omega$ et $\P$ une (loi de) probabilté sur $(\Omega, \Tribu)$, à savoir $\P$ est une application de $\Tribu$ dans $\cc{0,1}$ telle que
  - $\P(\Omega) = 1$
  - Pour toute suite d’événements $A_{n} \in \Tribu$ deux à deux disjoints, la suite $\big(\P(A_{n})\big)_{n \in \N}$ est sommable et
    $$
      \sum_{n \in \N}\P(A_{n}) = \P \left(\biguplus_{n \in \N}A_{n}\right)
    $$
    (propriété de _$\sigma$-additivité_).
%

%eg
  Soit $\omega \in \Omega$. Posons
  $$
    \delta_{\omega}: \applic{\Tribu}{\cc{0,1}}{A}{\begin{cases}1 \if \omega \in A \\ 0 \else\end{cases}}
  $$
  - $\delta$ est à valeurs dans $\cc{0,1}$ et définie sur $\Tribu$
  - $\delta_{\omega}(\Omega) = 1$ car $\omega \in \Omega$
  - Soit $(A_{n})_{n \in \N}$ une suite d’éléments deux à deux disjoints de la tribu $\Tribu$.
    - si $\omega \in \biguplus_{n \in \N}A_{n}$, alors
      $$
        \delta_{\omega} \left(\biguplus_{n \in \N}A_{n}\right) = 1
      $$
      Il existe donc $n_{0} \in \N$ tel que $\omega \in A_{n_{0}}$ et $\forall n \in \N \setminus \{n_{0}\}, \omega \notin A_{n}$. Alors $\delta_{\omega}(A_{n_{0}}) = 1$ et $\delta_{\omega}(A_{n}) = 0$ pour $n\ne n_{0}$ donc $\big(\delta_{\omega}(A_{n})\big)_{n \in \N}$ est sommable et
      $$
        \sum_{n \in \N}\delta_{\omega}(A_{n}) = 1 = \delta_{\omega} \left(\biguplus_{n \in \N} A_{n}\right)
      $$
    - sinon, $\omega \notin \biguplus_{n \in \N}A_{n}$. Alors $\forall n \in \N, \delta_{\omega}(A_{n}) = 0$ donc $\big(\delta_{\omega}(A_{n})\big)_{n \in \N}$ est sommable et
      $$
        \sum_{n \in \N}\delta_{\omega}(A_{n}) = 0 = \delta_{\omega} \left(\biguplus_{n \in \N} A_{n}\right)
      $$
    Ainsi, $\delta_{\omega}$ est une probabilité sur $(\Omega,\Tribu)$.
%

%prop
  Soit $(\Omega, \Tribu, \P)$ un espace probabilisé.
  1. $\P(\emptyset) = 0$
  2. Si la suite $(A_{d})_{d \in D}$ est une famille d’événements deux à deux disjoints indexée par un ensemble au plus dénombrable $D$, alors $\big(\P(A_{d})\big)_{d \in D}$ est sommable et
     $$
        \sum_{d \in D}\P(A_{d}) = \P \left(\biguplus_{d \in D}A_{d}\right)
     $$
  3. $\forall A \in \Tribu, \P(A^{\complement}) = 1-P(A)$
  4. $\P$ **est croissante**, i.e.
     $$
       \forall (A,B) \in \Tribu^{2}, A \subset B \implies \P(A) \leq \P(B)
     $$
     Précisément, si $A \subset B$, alors
     $$
       \P(B) - \P(A) = \P(B \setminus A)
     $$
  5. %callout
       Si $(A_{n})_{n \in \N}$ est une suite croissante d’événements, alors
       $$
         \P \left(\upbigcup_{n \in \N}A_{n}\right) = \lim_{n \to +\infty}\P(A_{n})
       $$
       (propriété de continuité croissante d’une probabilité).
     %
  6. Si $(B_{n})_{n \in \N}$ est une suite décroissante d’événements, alors
     $$
       \P \left(\downbigcap_{n \in \N}B_{n}\right) = \lim_{n\to+\infty}\P(B_{n})
     $$
     (propriété de continuité décroissante d’une probabilité).
  7. De façon plus générale, si $(A_{n})_{n \in \N}$ est une suite d’événements, alors
     $$
       \P \left(\bigcup_{n \in \N} A_{n}\right) = \lim_{N\to+\infty} \left(\bigcup_{n \in \icc{0,N}} A_{n}\right)
     $$
     et
     $$
       \P \left(\bigcap_{n \in \N} A_{n}\right) = \lim_{N\to+\infty} \P \left(\bigcap_{n \in \icc{0,N}}A_{n}\right)
     $$
  8. Si $(A_{n})_{n \in \N}$ est une suite d’événements, alors
     $$
       \P \left(\bigcup_{n \in \N} A_{n}\right) \leq \sum_{n \in \N}\P(A_{n})
     $$
     (inégalité de Boole dans $\bar{\R_{+}}$).
%

%proof
  1. $\emptyset \in \Tribu$ et $\emptyset \cap \emptyset = \emptyset$ donc $\big(\P(\emptyset)\big)_{n \in \N}$ est sommable. Nécessairement, $\P(\emptyset) = 0$.
  2. - Si $D$ est dénombrable, alors pour une bijection $\varphi: \N \longrightarrow D$,
       $$
         \big(\P(A_{d})\big)_{d \in D} \in \ell^{1}(D) \iff \big(\P(A_{\varphi(n)})\big)_{n \in \N} \in \ell^{1}(\N)
       $$
       donc $\big(\P(A_{d})\big)_{d \in D} \in \ell^{1}(\D)$ et
       $$
         \sum_{d \in D}\P(A_{d}) = \sum_{n \in \N}\P(A_{\varphi(n)}) = \P \left(\biguplus_{n \in \N}A_{\varphi_{n}}\right) = \P \left(\biguplus_{d \in D}A_{d}\right)
       $$
     - Si $D$ est finie, notons $D = \{d_{1}, \ldots, d_{n}\}$ et $B_{i} = A_{d_{i}}$. Posons pour $k \geq n+1, B_{k+1} = \emptyset \in \Tribu$. On a
       $$
         \forall (n,m) \in \N^{*}, \big(n\ne m \implies  B_{n} \cap B_{m} = \emptyset\big)
       $$
       donc
       $$
         \sum_{n \in \N^{*}} \P(B_{n}) = \P \left(\biguplus_{n \in \N^{*}}B_{n}\right)
       $$
  3. $\P(\Omega) = \P(A \biguplus A^{\complement}) = \P(A) + \P(A^{\complement})$ d’où $\P(A^{\complement}) = 1 - \P(A)$
  4. Soit $(A,B) \in \Tribu^{2}$ avec $A \subset B$. On a $B = (B \setminus  A)\uplus A$ d’où
      $$
        \P(B) = \P(B \setminus A) + \P(A) \geq \P(A)
      $$
      et $\P(B) - \P(A) = \P(B \setminus A)$.
  5. Soit $(A_{n})_{n \in \N}$ une suite croissante d’événements.
     $$
       \upbigcup_{n \in \N}A_{n} = A_{0} \uplus \left(\biguplus_{n \in \N}(A_{n+1} \setminus A_{n})\right)
     $$
     donc
     $$
       \P \left(\upbigcup_{n \in \N} A_{n}\right) = \P(A_{0}) + \sum_{n \in \N}\P(A_{n+1} \setminus A_{n})
     $$
     or $\forall n \in \N, A_{n} \subset A_{n+1}$ donc
     $$
       \P \left(\upbigcup_{n \in \N}A_{n}\right) = \P(A_{0}) + \sum_{n \in \N}\P(A_{n+1}) - \P(A_{n}) = \lim_{N\to+\infty} \P(A_{0}) + \sum_{n=1}^{N} \P(A_{n+1}) - \P(A_{n})
     $$
     Ainsi,
     $$
       \P \left(\upbigcup_{ n \in \N}A_{n}\right) = \lim_{N\to+\infty}\P(A_{n+1})
     $$
  6. $\P \left(\downbigcap_{n \in \N}B_{n}\right) = 1 - \P \left(\upbigcup_{n \in \N} B_{n}^{\complement}\right) = \lim_{n\to+\infty} \left(1- \P(B_{n}^{\complement})\right) = \lim_{n\to+\infty} \P(B_{n})$
  7. $\P \left(\bigcup_{n \in \N} A_{n}\right) = \P \left(\upbigcup_{n \in \N} \left(\bigcup_{ k \in \icc{0,n}}A_{k}\right)\right) = \lim_{n\to+/nff}\P \left(\bigcup_{k \in \icc{0,n}A_{k}}\right)$ donc
     $$
       \P \left(\bigcap_{n \in \N}A_{n}\right) = 1 - \P \left(\bigcup_{n \in \N}A_{n}^{\complement}\right) = \lim_{n\to+\infty} 1 - \P \left(\bigcup_{k \in \icc{1,n}}A_{k}^{\complement}\right)
     $$
  8. $\forall (A,B) \in \Tribu^{2}, \P(A \cup B) + P(A \cup B) = \P(A) + \P(B)$ or $A \cup B = (A \setminus B)\uplus (B \setminus A) \cup (A \cap B)$ donc
     $$
       \P(A \cup B) = \P(A \setminus B) + \P(B \setminus A) + \P(A \cap B) = \P(A \setminus (A \cap B)) + \P(B \setminus (A \cap B)) + \P(A \cap B) = \P(A) - \P(A \cap B) + \P(B)-\P(A \cap B) + \P( \cap B)
     $$
     - Soit $(A_{n})_{n \in \N}$ une suite d’événements.
       $$
         \forall (A,B) \in \Tribu^{2}, \P(A \cup B) = \P(A) + \P(B) - \P(A \cap B) \leq \P(A) + \P(B)
       $$
       Par récurrence, on a (la première inégalité est dans $\R_{+}$ et la seconde dans $\bar{\R_{+}}$)~:
       $$
         \forall n \in \N, \P \left(\bigcup_{k = 0}^{n} A_{k}\right) \leq \sum_{k \in \icc{0,n}}\P(A_{k}) \leq \sum_{k \in \N}\P(A_{k})
       $$
       On ppasse à la limite lorsque $n$ tend vers $+\infty$~:
       $$
         \P \left(\bigcap_{k \in \N}A_{k}\right) \leq \sum_{k \in \N}\P(_{k}) \dans \bar{\R_{+}}
       $$
%

## Distribution de probabilté discrète

%def
  Soit $\Omega$ un ensemble. On appelle _distribution de probabilité discrète_ sur $\Omega$ toute famille $(q_{\omega})_{\omega \in \Omega}$ de réels positifs telle que
  ~ $(q_{\omega})_{\omega \in \Omega} \in \ell^{1}(\Omega)$  ~ $\sum_{\omega \in \Omega} q_{\omega} = 1$
  Le _support_ de $(q_{\omega})$, à savoir $S = \{\omega \in \Omega \where q_{\omega} > 0\}$ est au plus dénombrable !
%

%proof
  On a
  $$
    S = \bigcup_{n \in \N^{*}} \underbrace{\left\{\omega \in \Omega \where q_{\omega} > \frac{1}{n}\right\}}_{S_{n}}
  $$
  donc
  $$
    (q_{\omega})_{\omega \in \Omega} \in \ell^{1}(\Omega) \implies (q_{\omega})_{\omega \in S_{n}} \in \ell^{1}(S_{n}) \implies  \left(\frac{1}{n}\right)_{\omega \in S_{n}} \in \ell^{1}(S_{n}) \implies  S_{n} \text{ fini}
  $$
%

%eg
  Posons, pour tout $x \in \R \setminus \N^{*}$, $q_{x} = 0$ et pour tout entier $n$ non nul, $q_{x} = \frac{6}{\pi^{2}x^{2}}$. On a pour tout réel $x$, $q_{x} \geq 0$ et
  $$
    \sum_{x \in \R} q_{x} = \sum_{n \in \N^{*}}\frac{6}{\pi^{2} x^{2}} = 1
  $$
  donc $(q_{x})$ est une distribution de probabilité sur $\R$.
%

%prop
  Soit $\Omega$ une distrbution de probabilité discrète $(q_{\omega})_{\omega \in \Omega}$. L’application
  $$
    \P: \applic{\Part(\Omega)}{\cc{0,1}}{A}{\sum_{\omega \in A} q_{\omega}}
  $$
  est une probabilité sur $(\Omega, \Part(\Omega))$ appelé probabilité associée à $(q_{\omega})_{\omega \in \Omega}$. On a en particulier
  $$
    \forall \omega \in \Omega, \P(\{\omega\}) = q_{\omega}
  $$
  et c’est la seule à vérifier cette propriété.
%

%proof
  _Analyse._ Soit $\P: \Part(\Omega) \longrightarrow \cc{0,1}$ une probabilité vérifiant $\forall \omega \in \Omega, \P(\{\omega\}) = q_{\omega}$. Soit $S = \{\omega \in \Omega \where q_{\omega} > 0\}$. C’est un ensemble au plus dénombrable. Soit $A \in \Part(\Omega)$. On a
  $$
    A = \big(A \cap S\big) \uplus \big(A \cap S^{\complement}\big)
  $$
  Par additivité de $\P$, on a
  $$
    \P(A) = \P(A \cap S) + \P(A \cap S^{\complement})
  $$
  or $\P(A \cap S^{\complement}) \leq \P(S^{\complement})$ par croissance de $\P$ et
  $$
    \begin{align*}
      \P(S^{\complement}) &= 1-\P(S) \\ &= 1-\P \left(\biguplus_{\omega \in S}\{\omega\}\right) \\ &= 1- \sum_{\omega \in S}q_{\omega} & \text{($\sigma$-additivité)} \\ &= 1- \sum_{\omega \in \Omega}q_{\omega} = 0
    \end{align*}
  $$
  Par positivité de $\P$, on a $\P(A \cap S^{\complement}) = 0$ donc $\P(A) = \P(A \cap S) = \sum_{\omega \in A \cap S} \P(\{\omega\})$ car $A \cap S$ est au plus dénombrable, d’où
  $$
    \P(A) = \sum_{\omega \in A \cap S}q_{\omega} = \sum_{\omega \in A}q_{\omega}
  $$

  _Synthèse._ Soit $A \in \P(\Omega)$. On a $(q_{\omega})_{\omega \in \Omega} \in \ell^{1}(\Omega)$ donc $(q_{\omega})_{\omega \in A} \in \ell^{1}(A)$ et
  $$
    0 \leq \sum_{\omega \in A}q_{\omega} \leq \sum_{\omega \in \Omega} q_{\omega} = 1
  $$
  donc
  $$
    \P: \applic{\Part(\Omega)}{\cc{0,1}}{A}{\P(A) = \sum_{\omega \in A} q_{\omega}}
  $$
  est correctement définie.
  - $\P(\Omega) = \sum_{\omega \in \Omega}q_{\omega} = 1$
  - Soit $(A_{n})_{n \in \N}$ une suite de parties de $\Omega$ deux à deux disjointes.
    $$
      \begin{align*}
        \P \left(\biguplus_{n \in \N}A_{n}\right) &= \sum_{\omega \in \biguplus_{n \in \N}A_{n}}q_{\omega} \\
        &= \sum_{\omega \in \biguplus_{n \in \N} (A_{n} \cap S)}q_{\omega} \\
        &= \sum_{n \in \N} \left(\sum_{\omega \in A_{n}}q_{\omega}\right) = \sum_{n \in \N}\P(A_{n})
      \end{align*}
    $$
%

%prop
  1. Si $\Omega$ est un ensemble au plus dénombrable, alors toutes les probabilités sur $(\Omega, \Part(\Omega))$ sont des probabilités associées à des distributions de probabilité discrètes sur $\Omega$.
  %offprog
    2. On peut remplacer $\Omega$ par $\R$ ci-dessus. Alors, si $(q_{\omega})_{\omega \in \R} \in \ell^{1}(\R)$, il existe un ensemble $D$ au plus dénombrable tel que $\forall x \in \R \setminus D, q_{x} = 0$. Ces probabilités ne sont pas intéressantes. C’est la raison pour laquelle on rejette l’étude de la tribu $\P(\R)$. _(Ulam, 1930)._
  %
%

%proof
  1. Soit $\Omega$ au plus dénombrable. Soit $\P: \Part(\Omega) \longrightarrow \cc{0,1}$ une probabilité sur $(\Omega, \Part(\Omega))$. Posons, pour tout $\omega \in \Omega$, $\P(\{\omega\}) = q_{\omega}$. On a pour tout $\omega \in \Omega$, $q_{\omega} \geq 0$ et
     $$
       \sum_{\omega \in \Omega}q_{\omega} = \sum_{\omega \in \Omega}\P(\{\omega\}) = \P \left(\biguplus_{\omega \in \Omega}\{\omega\}\right) = \P(\Omega) = 1
     $$
     donc $(q_{\omega})_{\omega \in \Omega}$ est une distribution de probabilité discrète sur $\Omega$. Pour $A \in \Part(\Omega)$, on a
     $$
       \sum_{\omega \in A}q_{\omega} = \sum_{\omega \in A}\P(\{\omega\}) = \P \left(\biguplus_{\omega \in A}\{\omega\}\right) = \P(A)
     $$
  %offprog
    2. Le résultat découle de l’axiome du choix.
  %
%

++Lois de probabilité usuelles sur les ensembles au plus dénombrables.++
- $(\Omega = \{0,1\}, \Part(\Omega))$. Soit $p \in \oo{0,1}$. L’unique probabilité $\P$ sur $(\Omega, \Part(\Omega))$ associée à la distribution discrète $(1-p,p)$ sur $\Omega$ est appelée _loi de Bernoulli de paramètre $p$_ et on note $\P = \B(p)$. On a donc
  ~ $\P(\{1\}) = p$  ~ $\P({0}) = 1-p$
- Soit $\Omega$ fini de cardinal non nul. L’unique probabilité $\P$ sur $(\Omega, \Part(\Omega))$ associéè à la distribution $\left(\frac{1}{\abs{\Omega}}\right)_{\omega \in \Omega}$ est appelée _loi uniforme sur $\Omega$_. On la note $\P = \Unif(\Omega)$. On a
  $$
    \forall \omega \in \Omega, \P(\{\omega\}) = \frac{1}{\abs{\Omega}}
  $$
- Soit $n \in \N^{*}$. Soit $p \in \oo{0,1}$. Considérons $\Omega = \icc{0,n}$. L’unique probabilité $\P$ sur $(\Omega, \Part(\Omega))$ associée à la distribution
  $$
    \left(\binom{n}{k}p^{k}(1-p)^{n-k}\right)_{k \in \icc{0,n}}
  $$
  est appelée _loi binomiale de paramètres $(n,p)$_. Elle est notée $\P = \B(n,p)$ et on a
  $$
    \forall k \in \icc{0,n}, \P(\{k\}) = \binom{n}{k}p^{k}(1-p)^{n-k}
  $$
  On a $\B(1,p) = \B(p)$.
- Considérons $\Omega = \N^{*}$. Soit $p \in \oo{0,1}$. $\left(p(1-p)^{k-1}\right)_{n \in \N^{*}}$ est une distribution de probabilité sur $\N^{*}$. La probabilté $\P$ sur $(\N^{*}, \Part(\N^{*}))$ associée à cette distribution est appelée _loi géométrique_ de paramètre $p$ et notée $\P = \mathscr G(p)$. On a donc
  $$
    \forall k \in \N^{*}, \P(\{k\}) = p(1-p)^{k-1}
  $$
  %proof
    Pour tout $n \in \N^{*}$, $p(1-p)^{k-1} \geq 0$ et
    $$
      \sum_{k \in \N^{*}}p(1-p)^{k-1} = \sum_{k \in \N}p(1-p)^{k} = p \times \frac{1}{1-(1-p)} = 1
    $$
  %
  %eg
    Pour $\P = \mathscr G(p)$ où $p \in \oo{0,1}$,
    $$
      \P(2\N*) = \sum_{k \in \N^{*}}p(1-p)^{2k-1} = \frac{p}{1-p} \sum_{k \in \N^{*}} \big[(1-p)^{2}\big]^{k} = \frac{p}{1-p} \times \frac{(1-p)^{2}}{1-(1-p)^{2}} = \frac{1-p}{2-p}
    $$
  %
- Pour $\Omega = \N$, soit $\lambda \in \lambda \in \R_{+}^{*}$. $\left(e^{-\lambda} \frac{\lambda^{k}}{k!}\right)_{k \in \N}$ est une distribution de probabilité sur $\N$. La probabilité $\P$ sur $(\N, \Part(\N))$ associée à cette distribution est appelée _loi de Poisson de paramètre $\lambda$_. Elle est notée $\P = \Poisson(\lambda)$. On a alors
  $$
    \forall k \in \N, \P(\{k\}) = e^{-\lambda}\frac{\lambda^{k}}{k!}
  $$
  %eg
    $$
      \P(2\N) = \sum_{k \in \N} e^{-\lambda}\frac{\lambda^{2k}}{(2k)!} = e^{-\lambda}\ch \lambda = \frac{1+e^{-2 \lambda}}{2}
    $$
    et
    $$
      \P(2\N+1) = \frac{1-e^{-2 \lambda}}{2}
    $$
    donc $\P(2\N+1) < \P(2\N)$.
  %

## Événements indépendants

%def
  Soit $(\Omega, \Tribu, \P)$ un espace probabilité.
  1. Soit $(A,B) \in \Tribu^{2}$. On dit que $A$ et $B$ sont $\P$-indépendants si
     $$
       \P(A \cap B) = \P(A)\P(B)
     $$
  2. Soit $(A_{i})_{i \in I}$ une famille d’événements indexée par un ensemble non vide $I$.
     - $(A_{i})_{i \in I}$ est une famille d’événements 2 à 2 $\P$-indépendants si
       $$
         \forall (i,j) \in I^{2}, i \ne j \implies \P(A_{i} \cap A_{j}) = \P(A) \P(A_{j})
       $$
     - $(A_{i})_{i \in I}$ est une famille d’événements $\P$-mutuellement indépendants si pour toute famille **finie** (non vide) $J$ de $I$, on a
       $$
         \P \left(\bigcap_{i \in J}A_{n}\right) = \prod_{i \in J} \P(A_{i})
       $$
%

%callout Attention
  L’indépendance mutuelle implique l’indépendance 2 à 2 mais la réciproque est fausse.
%

%eg
  Considérons $\Omega = \icc{1,4}$ et $\P = \Unif(\Omega)$. Soient $A = \{1,2\}$, $B = \{1,3\}$ et $C = \{2,4\}$.
  $$
    \P(A \cap B) = \P(\{1\}) = \frac{1}{4} = \P(A) \times \P(B)
  $$
  et de même, $\P(A \cap C) = \P(A)\P(C)$ et $\P(B \cap C) = \P(B)\P(C)$. Or
  $$
    \P(A \cap B \cap C) = \P(\{1\}) = \frac{1}{4} \ne \P(A)\P(B)\P(C)
  $$
%

%property
  Soit $(\Omega, \Tribu, \P)$ un espace probabilisé.
  1. Si $A$ et $B$ sont deux événements indépendants, alors $A$ et $\bar{B}$ le sont aussi.
  2. Soit $(A_{i})_{i \in I}$ une famille d’événements mutuellement indépendants. Alors
     - Si $J$ et $K$ sont deux parties finies disjointes de $I$, alors les événements $\bigcap_{i \in J}A_{i}$ et $\bigcap_{i \in K}A_{i}$ sont indépendants.
     - La famille $(B_{i})_{i \in I}$ avec $B_{i} \in \{A_{i}, \bar{A_{i}}\}$ est constituée d’événements mutuellement indépendants.
%

%proof
  1. On a $A = (A \cap B)\uplus (A \cap \bar{B})$ donc
     $$
       \P(A) = \P(A \cap B) + \P(A \cap \bar{B}) = \P(A)\P(B) + \P(A \cap \bar{B})
     $$
     donc
     $$
       \P(A \cap  \bar{B}) = \P(A)(1-\P(B)) = \P(A)\P(\bar{B})
     $$
  2. - $$
         \begin{align*}
           \P \left(\bigcap_{i \in J} A_{i} \cap  \bigcap_{i \in K}A_{i}\right) &= \P \left(\bigcap_{i \in I \uplus K}A_{i}\right) \\
           &= \prod_{i \in J \uplus K}\P(A_{i}) & \text{(mutuelle indépendance)}\\
           &= \prod_{i \in J}\P(A_{i}) \times \prod_{i \in K}\P(A_{i})\\
           &= \P \left(\bigcap_{i \in I}A_{i}\right) \times  \P \left(\bigcap_{i \in K}A_{i}\right)
         \end{align*}
       $$
     - Considérons la propriété
       $$
         \Prop(k): « \begin{cases}\P \left(\bigcap_{j \in J} A_{j} \cap \bigcap_{\ell \in K}\bar{A_{\ell}}\right) = \prod_{j \in J}\P(A_{j}) \times \prod_{\ell \in K}\P(\bar{A_{\ell}}) \\ \text{$J \subset I$ fini et $K \subset I$ disjoints tels que $\abs{K} = k$}\end{cases} »
       $$
       - $\Prop(0)$ est vraie par indépendance mutuelle des $A_{i}$.
       - Supposons $\Prop(0), \ldots, \Prop(k)$ vraies pour $k < \abs{I}$ fixé dans $\N$. Soit $J$ fini et $K$ de cardinal $k+1$ tels que $J \cap K = \emptyset$. Soit $i \in K$. $(A_{i}) \cup (A_{j})_{j \in J} \cup \big(\bar{A_{\ell}}\big)_{\ell \in K \setminus \{i\}}$ est une famille d’événements _mutuellement indépendants_ d’après $\Prop(0), \ldots, \Prop(k)$ donc $\left(\bigcap_{j \in J}A_{j}\right) \cap \left(\bigcap_{\ell \in k \setminus \{i\}}\bar{A_{\ell}}\right)$ et $A_{i}$ sont des événements indépendants donc les événements $\left(\bigcap_{j \in J}A_{j}\right) \cap \left(\bigcap_{\ell \in k \setminus \{i\}}\bar{A_{\ell}}\right)$ et $\bar{A_{i}}$ sont indépendants. Ainsi,
         $$
           \begin{align*}
             \P \left( \left(\bigcap_{j \in J} A_{j} \cap  \bigcap_{\ell \in K \setminus \{i\}} \bar{A_{\ell}}\right) \cap \bar{A_{i}}\right) &= \P \left(\bigcap_{j \in J}A_{j} \cap \bigcap_{\ell \in K \setminus \{i\}}\bar{A_{\ell}}\right) \times \P(\bar{A_{i}}) \\
             &\ueq{\Prop(k)} \prod_{j \in J}\P(A_{j}) \times \prod_{\ell \in K \setminus \{i\}}\P(\bar{A_{\ell}}) \times \P(\bar{A_{i}})
           \end{align*}
         $$
%

%callout Attention
  Soit $(A_{n})_{n \in \N}$ une famille d’événements. L’indépendance mutuelle des $A_{n}$ n’est pas équivalente à
  $$
    \forall n \in \N, \P \left(\bigcap_{k=0}^{n}A_{k}\right) = \prod_{k=0}^{n}\P(A_{k})
  $$
  %eg
    Par exemple pour $\Omega = \icc{1,8}$ et $\P = \Unif(\Omega)$, si on pose $A_{1} = \{1,2,3,4\}$, $A_{2} = \{3,4,5,6\}$ et $A_{3} = \{1,2,3,5\}$, on a
    - $\P(A_{1} \cap A_{2}) = \frac{1}{4} = \P(A_{1})\P(A_{2})$
    - $\P(A_{1} \cap  A_{2} \cap A_{3}) = \P(\{3\}) = \frac{1}{8} = \P(A_{1})\P(A_{2})\P(A_{3})$
    - $\P(A_{1} \cap A_{3}) = \frac{3}{8} \ne \P(A_{1})\P(A_{3})$
  %
%

%rem
  Soit $(\Omega, \Tribu, \P)$ un espace probabilisé. Soit $A$ un événement.
  $$
    \P(\Omega \cap A) = \P(A) = \P(A)\P(\Omega)
  $$
  donc $\Omega$ et $A$ sont indépendants donc $\emptyset$ et $A$ le sont aussi.
  $$
    \P(A \cap A) = \P(A)^{2} \iff \P(A) = \P(A)^{2} \iff \P(A) \in \{0,1\}
  $$
%

## Événements de probabilité 0 ou 1

Soit $\Omega_{1} = \{(0)_{n \in \N}\} \cup \{(1)\} \cup \{(0, \ldots, 0,1) \where n \in \N^{*}\}$. On pose $\P_{1}(\{(1)\})= \frac{1}{2}$ et
$$
  \forall n \in \N^{*}, \P_{1}(\{(0, \ldots, 0,1)\}) = \left(\frac{1}{2}\right)^{n+1}
$$
On peut alors étendre $\P_{1}$ de façon unique en une probabilité sur $(\Omega_{1}, \Part(\Omega_{1}))$ si on pose
$$
  \P_{1}(\{(0)_{n \in \N^{*}}\}) = 1- \frac{1}{2} - \sum_{n \in \N^{*}} \left(\frac{1}{2}\right)^{n+1} = 1- \sum_{k \in \N^{*}} \left(\frac{1}{2}\right)^{n} = 1 - \frac{1}{2} \times  \frac{1}{1-\frac{1}{2}} = 0
$$

%def
  Soit $(\Omega, \Tribu,\P)$ un espace probabilisé.
  1. $A \in \Tribu$ est appelé événement _$\P$-négligeable_ si $\P(A) = 0$.
  2. $A \in \Tribu$ est appelé événement _$\P$-presque sûr_ si $\P(A) = 1$.
  On a alors $A$ presque sûr si et seulement si $A^{\complement}$ négligeable.
  3. Soit $\varphi(\omega)$ une assertion dépendante de $\omega \in \Omega$. Si $A = \{\omega \in \Omega \where \varphi(\omega)\}$ est un événement $\P$-presque sûr, alors on dit que $\varphi$ est une propriété _vraie $\P$-presque sùrement_.
%

%eg
  Les événements $\P_{1}$-négligeables de $\P(\Omega_{1})$ sont $\emptyset$ et $\{(0)_{n \in \N^{*}}\}$ donc les événemente $\P_{1}$-presque sûrs sont $\Omega_{1}$ et $\Omega_{1} \setminus \{(0)_{n \in \N^{*}}\}$.
  $$
    \Omega_{1} \setminus \{(0)_{n \in \N^{*}}\} = \{\omega \in \Omega_{1} \where \abs{\omega} < +\infty\}
  $$
  est un événement $\P$-presque sûr. Avoir une suite de lancers de longueur finie est une propriété vraie $\P_{1}$-presque sûrement. On peut donc dire « le jeu se termine presque sûrement ».
%

%prop
  Soit $(\Omega, \Tribu, \P)$ un espace probabilisé.
  1. Toute réunion au plus dénombrable d’événements $\P$-négligeables est $\P$-négligeable.
  2. Toute intersection au plus dénombrable d’événements $\P$-presque sûrs est un événement $\P$-presque sûr.
%

%proof
  Soit $D$ un ensemble au plus dénombrable. Soit $(A_{d})_{d \in D}$ une famille d’événements.
  1. Supposons $\forall d \in D, \P(A_{d})=0$. On a
     $$
       0 \leq \P \left(\bigcup_{d \in D}A_{d}\right) \leq \sum_{d \in D}\P(A_{d}) = 0
     $$
     donc $\P \left(\bigcup_{d \in D}A_{d}\right) = 0$.
  2. Supposons $\forall d \in D, \P(A_{d}) = 1$ donc $\forall d \in D, \P(\bar{A_{d}}) = 0$ donc $\bigcup_{d \in D}\bar{A_{d}}$ est négligeable donc $\bigcap_{d \in D} A_{d}$ est presque sûr.
%

%offprog
  %lemma Lemme de Borel-Cantelli
    Soit $(\Omega, \Tribu, \P)$ un espace probabilisé. Soit $(A_{n})_{n \in \N}$ une famille d’événements.
    1. Si $\sum_{n \geq 0}\P(A_{n})$ converge, alors
       $$
         \P \left(\limsup_{n \in \N}A_{n}\right) = 0
       $$
    2. Si les événements $(A_{n})$ sont mutuellement indépendants et $\sum_{n \geq 0}\P(A_{n})$ diverge, alors
       $$
         \P \left(\limsup_{n \in \N} A_{n}\right) = 1
       $$
       i.e. une infinité de $A_{n}$ est réalisé $\P$-presque sûrement.
  %

  %proof
    $\limsup_{n \in \N} A_{n} = \downbigcap_{n \in \N}\bigcup_{k \geq n}A_{k}$ donc
    $$
      \P \left(\limsup_{n \in \N}A_{n}\right) = \lim_{n\to+\infty} \P \left(\bigcup_{k \geq n}A_{k}\right)
    $$
    1. On a
       $$
         0 \leq \P \left(\bigcup_{k \geq n} A_{k}\right) \leq \sum_{k \in \icc{n,+\infty}}\P(A_{k}) = \sum_{k=n}^{+\infty}\P(A_{k}) \arrowlim{n\to+\infty} 0
       $$
       donc $\P \left(\limsup_{n \in \N}A_{n}\right) = 0$.
    2. $\P \left(\bigcup_{k \geq n}A_{k}\right) = \lim_{N \to+\infty}\P \left(\bigcup_{k=n}^{N}A_{k}\right)$ or
       $$
         \P \left(\bigcap_{k=n}^{N}\bar{A_{k}}\right) = \prod_{k=n}^{N}\P (\bar{A_{k}}) = \prod_{k=n}^{N}(1-\P(A_{k}))
       $$
       $\forall x \in \R, e^{x} \geq 1+x$ donc $\forall x \in \cc{0,1}, e^{-x} \geq 1 - x \geq 0$ d’où
       $$
         \P \left(\bigcap_{k=n}^{N}\bar{A_{k}}\right) \leq \prod_{k=n}^N e^{-\P(A_{k})} = e^{-\sum_{k=n}^{N}\P(A_{k})} \arrowlim{N\to+\infty}0
       $$
       donc $\lim_{N\to+\infty}\P \left(\bigcup_{k=n}^{N} A_{k}\right) = 1$, i.e. $\P \left(\bigcup_{k \geq n} A_{k}\right) = 1$ pour tout entier $n \in \N$, donc
       $$
         \P \left(\limsup_{n \in \N}A_{n}\right) = 1
       $$
  %

  %eg
    Considérons l’espace probabilisé $(\N^{*},\Part(\N^{*}))$. Peut-on trouver une probabilité $\P$ sur cet espace telle que $\forall \in n\N, \P(n \N^{*}) = \frac{1}{n}$ ?
    ~
    Soient $p_{1} < \cdots < p_{k}$ des nombres premiers. Supposons l’existence de $\P$.
    $$
      \P \big(p_{1}\N^{*} \cap  \cdots \cap p_{k}\N^{*}\big) = \P \big((p_{1} \cdots p_{k})\N^{*}\big) = \frac{1}{p_{1} \cdots p_{k}} = \prod_{i=1}^{k}\P(p_{i}\N^{*})
    $$
    donc $(p\N^{*})_{p \in \Prime}$ est une famille d’événements mutuellement indépendants. Or
    $$
      \left(\P(p\N^{*})\right)_{p \in \Prime} = \left(\frac{1}{p}\right)_{p \in \P} \notin \ell^{1}(\Prime)
    $$
    en effet,((Résultat démontré dans le DS n°4))
    $$
      \sum_{\substack{p \in \Prime \\ p \leq n}}\frac{1}{p} = \ln(\ln n) + O(1)
    $$
    donc $\P(\limsup_{p \in \Prime} (p\N^{*}))=1$ donc $\limsup_{p \in \Prime} (p\N^{*}) \ne\emptyset$ donc il existe un entier $n \in \N^{*}$ divisible par une infinité de nombres premiers, ce qui est faux. $\P$ n’existe donc pas.
  %
%

## Probabilité conditionnelle

Dans cette partie, $(\Omega,\Tribu, \P)$ est un espace probabilisé.

%def Définition-Proposition
  Soit $B \in \Tribu$ avec $\P(B) > 0$. L’application
  $$
    \P_{B}: \applic{\Tribu}{\cc{0,1}}{A}{\P_{B}(A) = \frac{\P(A \cap B)}{\P(B)}}
  $$
  est une probabilité sur $(\Omega, \Tribu)$ appelée _probabilité conditionnelle sachant $B$_. On note aussi((Attention, $A\mid B$ n’existe pas, ce n’est pas un événement mais une notation.))
  $$
    \forall A \in \Tribu, \P_{B} = ``P(A\mid B)"
  $$
  d’où
  $$
    \P(A \cap B) = ``\P(A\mid B)" \times \P(B)
  $$
%

%proof
  - $\forall A \in \Tribu, A \cap B \subset B$ donc $\forall A \in \Tribu, 0 \leq \P(A \cap B) \leq \P(B)$ donc $\forall A \in \Tribu, 0 \leq \frac{\P(A \cap B)}{\P(B)} \leq 1$
  - $\P_{B}(\Omega) = \frac{\P(\Omega \cap B)}{\P(B)} = \frac{\P(B)}{\P(B)} = 1$
  - Soit $(A_{n})_{n \in \N}$ une famille d’événements deux à deux disjoints.
    $$
      \P_{B} \left(\biguplus_{n \in \N}A_{n}\right) = \frac{\P  \left(\left(\biguplus_{n \in \N}A_{n}\right) \cap B\right)}{\P(B)} = \frac{\P \left(\biguplus_{n \in \N}(A_{n} \cap B)\right)}{\P(B)} = \frac{1}{\P(B)} \sum_{n \in \N}\P(A_{n} \cap B) = \sum_{n \in \N}\P_{B}(A_{n})
    $$
%

### Formule des probabiltés composées

%prop
  Soient $n \geq 2$ et $A_{n}, \ldots, A_{n}$ des événements tels que $\P(A_{2} \cap  \cdots \cap A_{n}) > 0$. Alors,
  $$
    \begin{align*}
      \P(A_{1} \cap \cdots \cap A_{n}) &= \P(A_{1} \mid A_{2} \cap \cdots \cap A_{n}) \\
      &\times  \P(A_{2} \mid A_{3} \cap \cdots \cap A_{n})\\
      &\vdots\\
      &\times \P(A_{n-1} \mid A_{n}) \times \P(A_{n})
    \end{align*}
  $$
%

%proof
  Pour tout $k \in \icc{2,n}$, $(A_{k} \cap \cdots \cap A_{n}) \supset (A_{2} \cap  \cdots \cap A_{n})$ donc $\P(A_{k} \cap \cdots \cap A_{n}) > 0$.
  $$
    \begin{align*}
      \left[\prod_{k=1}^{n-1}\P(A_{k} \mid A_{k+1} \cap \cdots \cap A_{n})\right] \times \P(A_{n}) &= \left[\prod_{k=1}^{n}\frac{\P(A_{k} \cap A_{k-1} \cap  \cdots \cap A_{n})}{\P(A_{k+1} \cap \cdots \cap A_{n})}\right] \times \P(A_{n}) \\
        &= \frac{\P(A_{1} \cap \cdots \cap A_{n})}{\P(A_{n})} \times \P(A_{n}) \\
        &= \P(A_{1} \cap \cdots \cap A_{n})
    \end{align*}
  $$
%

%eg Trousseau de clés
  On dispose de $n$ clés. Une seule ouvre la porte. Les clés sont identiques. On teste les clés les unes après les autres. Calculons la probabilité que la $k$-ième tentative ouvre la porte. Notons $A_{i}$ l’événement « le $i$-ième essai est un échec » et notons $\pi_{k} = \P(A_{1} \cap \cdots \cap A_{k-1} \cap \bar{A_{k}})$. On a
  $$
    \begin{align*}
      \pi_{k} &= \P(\bar{A_{k}} \mid A_{k-1} \cap \cdots \cap A_{1}) \times \P(A_{k-1}\mid A_{k-1} \cap \cdots \cap  A_{1}) \times \cdots \\
      &= \frac{1}{n-(k-1)} \times \frac{n-(k-2)-1}{n-(k-2)} \times  \cdots \times \frac{n-2}{n-1} \times  \frac{n-1}{n} \\
      &= \frac{1}{n}
    \end{align*}
  $$
%

### Formule des probabilités totales

%def
  Soit $D$ un ensemble au plus dénombrable. Une famille d’événements $(A_{d})_{d \in D}$ est appelé _système quasi-complet_ (d’événements) si
  - Les $A_{d}$ sont incompatibles (disjoints) deux à deux
  - $\P \left(\biguplus_{d \in D} A_{d}\right) = 1$
%

%rem
  Tout système complet au plus dénombrable d’événements est un système quasi-complet.
%

%prop Formule des probabilités totales
  Soit $(\Omega_{d})_{d \in D}$ un système quasi-complet d’événements. On a
  $$
    \forall A \in \Tribu, P(A) = \sum_{d \in D}\P(A \cap \Omega_{d}) = \sum_{\substack{d \in D\\ \P(\Omega_{d})>0}}\P(A \mid \Omega_{d})\P(\Omega_{d})
  $$
%

%proof
  On a
  $$
    A = \left(A \cap \biguplus_{d \in D} \Omega_{d}\right) \uplus \underbrace{\left(A \cap \bar{\biguplus_{d \in D}\Omega_{d}}\right)}_{A'}
  $$
  donc
  $$
    \P(A) = \P \left(\biguplus_{d \in D}A \cap \Omega_{d}\right) + \P(A')
  $$
  or $A' \subset \bar{\biguplus_{d \in D}\Omega_{d}}$ d’où $\P(A') \leq 1-\P \left(\biguplus_{d \in D}\Omega_{d}\right) = 0$ donc $\P(A')=0$. Ainsi,
  $$
    \P(A) = \sum_{d \in D}\P(A \cap \Omega_{d}) = \sum_{\substack{d \in D \\ \P(\Omega_{d}) > 0}}\P(A \cap \Omega_{d}) = \sum_{\substack{d \in D \\ \P(\Omega_{d}) > 0}}\P(A \mid \Omega_{d}) \P(\Omega_{d})
  $$
%

%eg
  Considérons un jeu de pile ou face infini. $\Omega_{2} = \{0,1\}^{\N^{*}}$ (0 pour pile et 1 pour face). La pièce est équilibrée ainsi~:
  ~ probabilité $p \oo{0,1}$ d’obtenir pile  ~ probabilité $q=1-p$ d’obtenir face.
  Notons $A_{n}$ l’événement « obtenir pour la première fois deux faces consécutives au n-ième lancer » et posons pour $n \in \N^{*}$, $a_{n} = \P(A_{n})$. On a
  ~ $a_{1} = \P(\emptyset) = 0$  ~ $a_{2} = q^{2}$  ~ $a_{3} = pq^{2}$
  Notons $P_{i}$ l’événement « obtenir pile au i-ème lancer » et $F_{i}$ l’événement « obtenir face au i-ème lancer ». $(P_{1}\Phi_{1})$ est un système complet d’événements, tout comme $(P_{1}, F_{1} \cap P_{2}, F_{1} \cap F_{2})$. Soit $n \geq 2$.
  $$
    \begin{align*}
      a_{n+2} = \P(A_{n+1}) &= \P(A_{n+2}\mid P_{1}) \times \P(P_{1}) \\
      &+ \P(A_{n+2} \mid F_{1} \cap P_{2}) \times \P(F_{1} \cap P_{2}) \\
      &+ \P(A_{n+2} \mid F_{1} \cap F_{2}) \times \P(F_{1} \cap F_{2}) \\
      &= \P(A_{n+1}) \times p + \P(A_{n})\times q \times p + 0
    \end{align*}
  $$
  donc $\forall n \geq 2, a_{n+2} = pa_{n+1} + pqa_{n}$ et cette formule est aussi vraie pour $n=1$ donc
  $$
    \forall n \in \N^{*}, a_{n+2} = p a_{n+1}+pqa_{n}
  $$
  On souhaite calculer
  $$
    s = \P \left(\biguplus_{n \geq 2}A_{n}\right) = \sum_{n=2}^{+\infty}\P(A_{n})
  $$
  On a
  $$
    s = a_{2} + \sum_{n=3}^{+\infty}p a_{n-1} + pqa_{n-2}
  $$
  soit $s = a_{2} + ps + pq \sum_{n=1}^{+\infty}a_{n}$ d’où $s = q^{2} + (p+pq)s$ donc $(q-pq)s = q^{2}$ i.e. $q^{2}s = q^{2}$ soit $s=1$. On obtient deux faces consécutifs $\P$-presque sûrement.
%

### Formule de Bayes

%prop
  Soit $(\Omega_{d})_{d \in D}$ un système quasi-complet. Soit $A \in \Tribu$ avec $\P(A) > 0$. On a, pour tout $d \in D$,
  $$
    \P(\Omega_{d} \mid  A) = \frac{\P(\Omega_{d} \cap A)}{\P(A)} = \frac{\P(\Omega_{d} \cap A)}{\sum_{d \in D}\P(\Omega_{d} \cap A)}
  $$
%

## Variables aléatoires réelles

%def
  Soit $(\Omega,\Tribu)$ un espace probabilisable. Soit $E$ un ensemble quelconque. Une application $X: \applic{\Omega}{E}{\omega}{X(\omega)}$ est appelée _variable aléatoire discrète_ sur $(\Omega, \Tribu)$ si
  - $X(\Omega)$ est une partie au plus dénombrable de $E$
  - $\forall x \in X(\Omega), \underbrace{X^{-1}(\{x\})}_{(X=x)} = \{\omega \in \Omega \where X(\omega) = x\} \in \Tribu$
  Si $E=\N$ (resp. $\Z,\R,\C$), alors $X$ est une variable aléatoire discrète entière (resp. entière, réelle, complexe) sur $(\Omega,\Tribu)$. On écrit alors $X \in L^{0}(\Omega,\Tribu)$.
%

%eg
  - Soit $A$ un événement. Considérons
    $$
      \1_{A}: \applic{\Omega}{\R}{\omega}{\begin{cases}1 \if \omega \in A \\ 0 \else\end{cases}}
    $$
    - $\1_{A}(\Omega) \subset \{0,1\}$
    - $\1_{A}^{-1}(\{1\}) = A \in \Tribu$ et $(\1_{A} = 0) = A^{\complement} \in \Tribu$
    donc $\1_{A} \in L^{0}(\Omega,\Tribu)$.
  - Soit $(A_{n})_{n \in \N^{*}}$ une suite d’événements deux à deux disjoints. Posons
    $$
      X: \applic{\Omega}{\R}{\omega}{\sum_{n=1}^{+\infty}\frac{1}{n}\1_{A_{n}}(\omega)}
    $$
    - $X(\Omega) \subset \{0\} \times \left\{\frac{1}{n}\where n \in \N^{*}\right\} \approx\N$ donc $X(\Omega)$ est au plus dénombrable.
    - pour tout $n \in \N^{*}$, $\left(X = \frac{1}{n}\right) = A_{n} \in \Tribu$ et
      $$
        (X=0) = \left(\bigcup_{n \in \N^{*}}A_{n}\right)^{\complement} = \bigcap_{n \in \N^{*}}A_{n}^{\complement} \in \Tribu
      $$
      donc $X \in L^{0}(\Omega,\Tribu)$.
%

%rem
  1. Si $X: \Omega \longrightarrow E$ est une variable aléatoire discrète sur $(\Omega,\Tribu)$, alors
     $$
       \forall A \in \Part(E), X^{-1}(A) \{\omega \in \Omega \where X(\omega) \in A\} \in \Tribu
     $$
     En effet,
     $$
       (X \in A) = \Big(X \in \big(A \cap X(\omega)\big)\Big) = \bigcup_{x \in \underbrace{A \cap X(\omega)}_{\text{au plus dénombrable}}}(X=x) \in \Tribu
     $$
  2. Si $X: \Omega \longrightarrow \R$ est une variable aléatoire (discrète) sur $(\Omega, \Tribu)$, alors
     $$
       \forall x \in \R, (X \leq x) = (X \in \oc{-\infty, x}) \in \Tribu
     $$
     et si $a < b$ sont deux réels, alors $(a < X < b) = (X \in \oo{a,b}) \in \Tribu$.
%

%prop
    Soit $X: (\Omega,\Tribu) \longrightarrow E$ une variable aléatoire discrète. Si $f: X(\Omega) \longrightarrow F$ est une application définie sur $X(\Omega)$, alors $f\circ X = ``f(X)": \applic{\Omega}{F}{\omega}{f(X(\omega))}$ est une variable aléatoire discrète sur $(\Omega,\Tribu)$.
%

%proof
  - $X(\Omega)$ est au plus dénombrable donc $``f(X)(\Omega)"=f(X(\Omega))$ est une partie au plus dénombrable de $F$.
  - Soit $x \in "f(X)"(\Omega)$.
    $$
      \big("f(X)" = x\big) = (f\circ X = x) = (X \in \underbrace{f^{-1}(\{x\})}_{\in \Part(E)}) \in \Tribu
    $$
%

%prop
  Soient $X_{1}, \ldots, X_{n}$ des applications de $\Omega$ dans respectivment $E_{1}, \ldots, E_{n}$. Posons
  $$
    Z: \applic{\Omega}{E_{1} \times \cdots \times E_{n}}{\omega}{\big(X_{1}(\omega), \ldots, X_{n}(\omega)\big)}
  $$
  Alors $Z$ est une variable aréatoire discrète sur $(\Omega,\Tribu)$ si et seulement si $X_{1}, \ldots, X_{n}$ le sont. Si tel est le cas, alors $Z$ est appelé _vecteur aléatoire_ de composante aléatoire $X_{1}, \ldots, X_{n}$.
%

%proof
  - Supposons que $Z$ est une variable aléatoire discrète. Soit $k \in \icc{1,n}$. Posons $\pi_{k}: \applic{E_{1} \times \cdots \times E_{n}}{E_{k}}{(x_{1}, \ldots, x_{n})}{x_{k}}$. Alors $\pi_{k}(Z) = X_{k}$ est alors une variable aléatoire discrète sur $(\Omega,\Tribu)$.
  - Supposons que $X_{1}, \ldots, X_{n}$ sont des variables aléatoires discrètes sur $(\Omega,\Tribu)$.
    - $Z(\Omega) \subset X_{1}(\Omega) \times \cdots \times X_{n}(\Omega)$ donc $X_{1}(\Omega) \times  \cdots \times X_{n}(\Omega)$ étant au plus dénombrable, $Z(\Omega)$ l’est également.
    - Soit $x \in Z(\Omega)$. Il existe $(x_{1}, \ldots, x_{n}) \in X_{1}(\Omega) \times \cdots \times X_{n}(\Omega)$ tel que $x = (x_{1}, \ldots, x_{n})$.
      $$
        (Z=x) = \big((X_{1}, \ldots, X_{n}) = (x_{1}, \ldots, x_{n})\big) = (X_{1}=x_{1}) \cap \cdots \cap (X_{n} = x_{n}) \in \Tribu
      $$
    donc $Z$ est une variable aléatoire discrète sur $(\Omega,\Tribu)$.
%

%cor
  1. $L^{0}_{\K}(\Omega,\Tribu)$ est une sous-algèbre de $(\K^{\Omega},+, \times, \cdot)$.
  2. Si $(X_{1}, \ldots, X_{n}) \in L^{0}_{\R}(\Omega,\Tribu)$, alors
     ~ $X_{1} + \cdots + X_{n}$  ~ $\abs{X_{1} + \cdots + X_{n}}$  ~ $\max(X_{1}, \ldots, X_{n})$  ~ $\min(X_{1}, \ldots, X_{n})$  ~ $\lambda_{1} X_{1} + \cdots + \lambda_{n}X_{n}$  ~ $X_{1} \times \cdots \times X_{n}$
     sont des variables aléatoires discrètes sur $(\Omega,\Tribu)$.
%

%proof
  1. $\1_{\Omega} = \tilde{1} \in L^{0}_{\K}(\Omega,\Tribu)$. Soit $(X,Y) \in L^{0}_{\K}(\Omega,\Tribu)^{2}$. Soit $(\lambda, \mu) \in \K^{2}$. Alors $Z = (X,Y) : \omega \longmapsto \big(X(\omega), Y(\omega)\big) \in \K^{2}$ est une variable aléatoire discrète. Si
     ~ $f: \applic{\K^{2}}{\K}{(x,y)}{\lambda x + \mu y}$  ~ $g: \applic{\K^{2}}{\K}{(x,y)}{x \times y}$
     alors $f(Z) = \lambda X + \mu Y \in L^{0}(\Omega,\Tribu)$ et $g(Z) = X \times Y \in L^{0}(\Omega,\Tribu)$.
  2. $Z = (X_{1}, \ldots, X_{n}): \Omega \longrightarrow \R^{n}$ est une variable aléatoire discrète si $h: \applic{\R^{n}}{\R}{(x_{1}, \ldots, x_{n})}{\min(x_{1}, \ldots, x_{n})}$ alors $h(2) = \min(X_{1}, \ldots, X_{n}) \in L^{0}(\Omega,\Tribu)$.
%


%def Définition-Proposition
  Soit $(\Omega,\Tribu,\P)$ un espace probabilisé. Soit $X: \Omega \longrightarrow E$ une variable aléatoire discrète sur $(\Omega,\Tribu)$. Alors,
  1. $\big((X=x)\big)_{x \in X(\Omega)}$ est un système complet (au plus dénombrable) d’événements de $\Tribu$.
  2. $\big(\P(X=x)\big)_{x \in X(\Omega)}$ est une distribution de probabilité discrète sur $X(\Omega)$.
  3. La probabilité sur $\big(X(\Omega), \Part(X(\Omega))\big)$ associée à cette distribution est appelée _loi de $X$_ et est notée $\P_{X}$. C’est donc l’unique probabilité sur $(X(\Omega), \Part(X(\Omega)))$ telle que
     $$
       \forall x \in X(\Omega), \P_{X}(\{x\}) \defeq \P(X=x)
     $$
     On a alors
     $$
       \forall A \in \Part(X(\Omega)), \P_{X}(A) = \P(X \in A)
     $$
%

%proof
  1. $\Omega = \biguplus_{x \in X(\Omega)} X^{-1}(\{x\}) = \biguplus_{x \in X(\Omega)}(X=x)$
  2. $\forall x \in X(\Omega), \P(X=x)\geq 0$ et
     $$
       \sum_{x \in X(\Omega)}\P(X=x) = \P \left(\biguplus_{x \in X(\Omega)}(X=x)\right) = \P(\Omega)=1
     $$
  3. $\P: \Tribu \longrightarrow \cc{0,1}$. $\P_{X}: \Part(X(\Omega)) \longrightarrow \cc{0,1}$. Soit $A \in \P(X(\Omega))$.
     $$
       \P_{X}(A) = \sum_{x \in A}\P(X=x) = \P \left(\biguplus_{x \in A}(X=x)\right) = \P(X \in A)
     $$
%


%eg
  Soit $A \in \Tribu \setminus \{\emptyset, \Omega\}$. $\1_{A}: \Omega \longrightarrow \R \in L^{0}(\Omega,\Tribu)$. $\P_{\1_{A}}$ est une probabilité sur $(\1_{A}(\Omega), \Part(\1_{A}(\Omega))) = (\{0,1\}, \Part(\{0,1\}))$ caractérisée par
  ~ $\P(\{0\}) = \P(\1_{A} = 0) = \P(A^{\complement})$  ~ $\P_{\1_{A}}(\{1\}) = \P(\1_{A} = 1) = \P(A)$
  donc $\P_{\1_{A}} = \B \big(\P(A)\big)$ ce qu’on écrit $\1_{A} \leadsto \P(A)$ et on dit que « $\1_{A}$ est la loi de Bernoulli de paramètre $\P(A)$ »
%

%prop
  Soit $(p_{x})_{x \in D}$ une distribution de probabilité discrète sur un ensemble au plus dénombrable $D$. Alors il existe une variable aléatoire $X$ dont la loi est la probabilité associée à cette distribution.
%

%proof
  Soit $\P$ la probabilité associée à cette distribution. Prenons
  $$
    X: \applic{(D,\Part(D),\P)}{D}{d}{d}
  $$
  Alors $X(D) = D$ est au plus dénombrable et $\forall d \in X(D), (X=d) = \{d\} \in \Part(D)$ donc $X$ est une variable aléatoire discrète. On a $\forall x \in X(D) = D$, $\P_{X}(\{x\}) = \P(X=x) = p_{x}$ donc  $\P_{X} = \P$.
%

%term
  Soient $X : (\Omega,\Tribu, \P) \longrightarrow E$ et $X': (\Omega', \Tribu', \P') \longrightarrow E'$ deux variables aléatoires discrètes. On dit que $X$ et $X'$ suivent la même loi si
  $$
    \forall x \in X(\Omega) \cap X'(\Omega'), \P(X=x) = \P'(X'=x)
  $$
  et
  $$
    \forall x \in X(\Omega) \sym X'(\Omega'), \P(X=x) = \P'(X'=x) = 0
  $$
  Ou, dans le cas $E = E'$ et $X(\Omega) = X'(\Omega')$, si $\P_{X} = \P_{X'}$.
  On écrit $X \sim X'$.
%

%eg
  1. Soit $X: (\Omega,\Tribu, \P) \longrightarrow \R$ une variable aléatoire discrète telle que $\P(X=1) = \P(X=-1) = \frac{1}{2}$ (variable aléatoire de _Rademacker_). Alors, $X \sim (-X)$.
  2. Soit $X$ une variable aléatoire réelle discrète. $X\leadsto \B(n,p)$ signifie qu’il existe un espace probabilisé $(\Omega,\Tribu,\P)$ telle que $X: (\Omega,\Tribu,\P) \longrightarrow \R$ soit une variable aléatoire discrète vérifiant
     $$
       \forall k \in \icc{0,n}, \P(X=k) = \binom{n}{k}p^{k}(1-p)^{n-k}
     $$
     (et donc $\forall x \in \R \setminus \icc{0,n}, \P(X=x) = 0$).
  3. $(\Omega_{1},\Part(\Omega_{1}), \P_{1})$ avec $\P_{1}$ définie par $\P\Big(\big\{(0)_{n \in \N^{*}}\big\}\Big)$ et $\P_{1}\Big(\big\{(0, \ldots, 0,1)\big\}\Big) = \left(\frac{1}{2}\right)^{n+1}$ pour tout $n \in \N$. Posons
     $$
       N: \applic{\Omega_{1}}{\N^{*} \cup \{\infty\}}{\omega}{\abs{\omega} \quad \text{(longueur de $\omega$)}}
     $$
     Alors
     - $N(\Omega_{1}) = \N^{*} \cup \{\infty\}$ est un ensemble dénombrable
     - $\forall \ell \in \N^{*} \cup \{\infty\}, (N=\ell) \in \Part(\Omega_{1})$
     donc $N$ est une variable aléatoire discrète sur $(\Omega_{1}, \Part(\Omega_{1}))$. Déterminons sa loi. On a $\P_{N}(\{\infty\}) = \P_{1}(N=\infty) = \P_{1}(\{(0)_{n \in \N}\}) = 0$ et
       $$
         \forall n \in \N^{*}, \P_{N}(\{n\}) = \P_{1}(N=n) = \P_{1}(\{(0, \ldots, 0, 1)\}) = \left(\frac{1}{2}\right)^{n}
       $$
       donc
       $$
         \forall n \in \N^{*}, \P(N=n) = \frac{1}{2}\left(1-\frac{1}{2}\right)^{n-1}
       $$
       donc $N \leadsto \mathscr G \left(\frac{1}{2}\right)$.
%

%prop
  Soit $\Big(X_{n}: (\Omega_{n},\Tribu_{n},\P_{n}) \longrightarrow \R\Big)_{n \in \N}$ une suite de variables aléatoires réelles discrètes.(($X_{n}$ compte le nombre de succès dans une succession de $n$ épreuves de Bernoulli indépendantes de probabilité de succès $p$.)) Soit $(p_{n})_{n \in \N} \in \oo{0,1}^{\N}$. Supposons
  ~ $\forall n \in \N, X_{n} \leadsto \B(n,p_{n})$  ~ $\exists \lambda > 0: n p_{n} \arrowlim{n\to+\infty} \lambda$
  Alors
  $$
    \forall k \in \N, \P_{n}(X_{n} = k) \arrowlim{n\to+\infty} e^{-\lambda} \frac{\lambda^{k}}{k!}
  $$
  i.e $\P_{X_{n}} \sarrowlim{n\to+\infty} \mathscr P(\lambda)$.
  $\mathscr P$ est appelée _loi des événements rares_: elle compte le nombre de succès dans une succession d’un grand nombre d’épreuves de Bernoulli indépendantes de probabilité de succès très faible.
%

%proof
  Soit $k \in \N$. Pour tout $n \geq k$,
  $$
    \begin{align*}
      P_{n}(X_{n} = k) &= \binom{n}{k}p_{n}^{k}(1-p_{n})^{n-k} \\
      &= \frac{n(n-1) \cdots (n-k+1)}{k!} p_{n}^{k} \frac{(1-p_{n})^{n}}{(1-p_{n})^{k}} \\
      &\usim{n\to+\infty} \frac{n^{k}}{k!}p_{n}^{k} \frac{(1-p_{n})^{n}}{1} \\
      &\usim{n\to+\infty} \frac{\lambda^{k}}{k!} e^{n\ln(1-p_{n})}
    \end{align*}
  $$
  car $p_{n} \sim \frac{\lambda}{n} \arrowlim{n\to+\infty}0$. Or $p_{n} \longrightarrow 0$ donc $n\ln(1-p_{n})\usim{n\to+\infty}-np_{n} \arrowlim{n\to+\infty}-\lambda$ donc par convexité de $\exp$, on a $e^{n\ln(1-p_{n})} \arrowlim{n\to+\infty}e^{-\lambda}$ d’où
  $$
    \P_{n}(X_{n} = k) \arrowlim{n\to+\infty} e^{-\lambda}\frac{\lambda^{k}}{k!}
  $$
%

%eg
  Une maladie rare touche en france chaque année 10 personnes en moyenne. Quelle est la probabilité pour qu’elle touche plus de 15 personnes en 2026 ?
  ~
  On peut considérer $X \leadsto \mathscr P(10)$ et on a alors
  $$
    \P(X > 15) = 1- \P(X \leq 15) = 1 - \sum_{k=0}^{15}e^{-10}\frac{10^{k}}{k!} \simeq 0.049
  $$
  Le calcul exact serait
  $$
    \sum_{k=16}^{66 \cdot 10^{6}}\binom{66 \cdot 10^{6}}{k}p^{k}(1-p)^{66 \cdot 10^{6} - k}
  $$
  avec $p = \frac{10}{66 \cdot 10^{6}}$.
%

%prop
  Soient $X: (\Omega, \Tribu, \P) \longrightarrow E$ et $Y: (\Omega', \Tribu', \P') \longrightarrow E$ deux variables aléatoires discrètes. Soit $f: E \longrightarrow F$ une application. On a
  $$
    X \sim Y \implies f(X) \sim f(Y)
  $$
%

%proof
  Supposons $X \sim Y$. Soit $x \in f(X)(\Omega) \cap f(Y)(\Omega)$. Montrons $\P(f(X) = x) = \P'(f(Y) = x)$. On a
  $$
    \begin{align*}
      \P(f(X) = x) &= \P(X \in f^{-1}(\{x\})) \\
      &= \P \left(\biguplus_{y \in f^{-1}(\{x\})}(X=y)\right) \\
      &= \P \left(\biguplus_{y \in \underbrace{f^{-1}(\{x\}) \cap X(\Omega)}_{\text{au plus dénombrable}}}(X=y)\right) \\
      &= \sum_{y \in f^{-1}(\{x\}) \cap X(\Omega)} \P(X=y) \\
      &= \sum_{k \in f^{-1}(\{x\}) \cap X(\Omega) \cap Y(\Omega)} \P(X=y) \\
      &= \sum_{y \in f^{-1}(\{x\}) \cap X(\Omega), \cap Y(\Omega)} \P'(Y=y) \\
      &= \P' \left(f(Y) = x\right)
    \end{align*}
  $$
  Soit $x \in f(X)(\Omega) \sym f(Y)(\Omega)$. Si $x \notin f(X)(\Omega)$, alors $0 = \P(f(X) = x) = \P(f(Y) = x)$.
%

%def
  Soit $X: (\Omega, \Tribu,\P) \longrightarrow E$ une variable aléatoire discrète. Soit $A$ un événement de probabilité non nulle. La loi de $X: (\Omega, \Tribu, \stress{\P_{A}}) \longrightarrow E$ est parfois notée $\P_{X\mid A}$ et s’appelle _loi conditionnelle de $X$ sachant $A$_. Elle est donc définie par
  $$
    \P_{X\mid A} : \applic{\Part(X(\Omega))}{\cc{0,1}}{B}{\P_{X\mid A}(B) = \P_{A}(X \in B) = \P(X \in B \mid A)}
  $$
%

%eg
  Soit $X \leadsto \mathscr G(p)$. $\P_{X\mid (X>n)}$ est caractérisée par la donnée de la distribution $\big(\P_{X\mid (X>n)}(\{k\})\big)_{k \in \N^{*}}$. On a, pour tout $k \in \N^{*}$,
  $$
    \P_{X\mid (X>n)} (\{k\}) = \P(X=k\mid X>n) = \begin{cases}0 \if k \in \icc{0,n} \\ \frac{\P((X=k) \cap (X>n))}{\P(X>n)} = \frac{\P(X=k)}{\P(X>n)} \if k \geq n+1\end{cases}
  $$
  donc
  $$
    \P_{X\mid (X>n)} (\{k\}) = \begin{cases}0 \if k \in \icc{0,n} \\ \frac{p(1-p)^{k-1}}{(1-p)^{n}} = p(1-p)^{k-n-1} \if k \geq n+1\end{cases}
  $$
%

%def
  Soit $Z = (X_{1}, \ldots, X_{n}): (\Omega, \Tribu,\P) \longrightarrow E_{1} \times  \cdots \times E_{n}$ un vecteur aléatoire discret. La loi de $Z$, notée $\P_{Z}$ est appelée _loi conjointe du vecteur aléatoire_ $(X_{1}, \ldots, X_{n})$. Elle est caractérisée par la donnée de la distribution
  $$
    \Big(\P\big(Z=(x_{1}, \ldots, x_{n})\big)\Big)_{(x_{1}, \ldots, x_{n}) \in Z(\Omega)} = \Big(\underbrace{\P \big((X_{1} = x_{1}) \cap  \cdots \cap (X_{n}=x_{n})\big)}_{\text{notée } \P(X_{1}=x_{1}, \ldots, X_{n}=x_{n})}\Big)_{(x_{1}, \ldots, x_{n}) \in Z(\Omega)}
  $$
  Les lois $\P_{X_{1}}, \ldots, \P_{X_{n}}$ sont appelées _lois marginales_.
%

%eg
  On a par exemple pour $x_{1} \in X_{1}(\Omega)$~:
  $$
    \begin{align*}
      \P_{X_{1}}(\{x_{1}\}) &= \P(X_{1} = x_{1}) \\&= \P \left(\biguplus_{(x_{2}, \ldots, x_{n}) \in X_{2}(\Omega) \times  \cdots \times X_{n}(\Omega)} (X_{1}=x_{1}, X_{2} = x_{2}, \ldots, X_{n} = x_{n})\right) \\&= \sum_{(x_{2}, \ldots, x_{n}) \in X_{2}(\Omega)\times  \cdots \times X_{n}(\Omega)}\P(Z=(x_{1}, \ldots, x_{n}))
    \end{align*}
  $$
  **La loi conjointe détermine les lois marginales mais la réciproque est fausse.** En effet, soient $(X,Y)$ et $(X',Y')$ deux couples aléatoires dont les lois conjointes sont déterminées par


  ```
    ┌─────┬─────┬─────┐  ┌─────┬─────┬─────┐
    │ X/Y │ y1  │ y2  │  │X'/Y'│ y1  │ y2  │
    ├─────┼─────┼─────┤  ├─────┼─────┼─────┤
    │ x1  │ 1/4 │ 1/4 │  │ x1  │ 1/8 │ 3/8 │
    ├─────┼─────┼─────┤  ├─────┼─────┼─────┤
    │ x2  │ 1/4 │ 1/4 │  │ x2  │ 3/8 │ 1/8 │
    └─────┴─────┴─────┘  └─────┴─────┴─────┘
  ```

  Alors
  ~ $\P(X=x_{1}) = \frac{1}{2} = \P(X=x_{2})$  ~ $\P(Y=y_{1}) = \frac{1}{2}= \P(Y=y_{2})$  ~ $\P(X' = x_{1}) = \frac{1}{8} + \frac{3}{8} = \frac{1}{2} = \P(X' = x_{2})$  ~ $\P(Y' = y_{1}) = \frac{1}{2} = \P(Y' = y^{2})$
  donc $X \sim X' \leadsto \mathscr \Unif(\{x_{1}, x_{2}\})$ et $Y \sim Y' \leadsto \Unif(\{y_{1}, y_{2}\})$ or $(X,Y) \not\sim (X',Y')$.
%
