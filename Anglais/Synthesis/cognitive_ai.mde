# Title goes here

The rise of AI radically changed the the way humans interact with machines, and thus the link which exists between them. The documents under study are closely related to this new consideration, with an article from The Verge dated febrary 2023 using the idea of a mirror test to question our vision of AI, an extract of Spike Jonze’s film **Her** released in 2013 in which is depicted an emotional relation between a human and a computer assistant, an illustration Elia Barbieri made for The Guardian in 2022, again using a mirror to interrogate our vision of robots, a diagram made by Dave Raggett for a scientific report about cognitive AI in 2020, explaining how a cognitive system can be implemented in computer science, and finally a review on the Pygmalion theater play written by George Bernard Shaw in 1913. So, are contemporary representations of AI bluring the lines between human and machines ? ==FIXME thesis question==

As depicted in **Her**, humans want to create links and share love, and conversational AI can help to fulfill this desire, sometimes by pushing the users of such services into thinking they are talking to a conscient intelligence, which obviously they don’t. Sometimes, users are well aware of the unconcious nature of the agent they are talking with, but they nontheless want to believe the program have something extraordinary they are feeling. This case is exposed in **The Verge**, where it is said influential tech writers felt this emotion after trying the latest version of a conversational model. Maybe this misconseption is helped by anthropomorphisme, the idea suggested by the **Guardian cartoon**, in which the reader is seeing a human figure reflected in the mirror, instead of the robot standing behind, as if humans had this curious temptation to grant human characteristics to robots or non-human entities in general, something even stronger as we are used to chat with a human by sending and receiving text messages, something an AI can reproduce almost perfectly.

Modern LLM are then build to ressemble to humans, to act and communicate like them. To achieve this goal, these/such programs are often (built) using a similar architecture as our brain or organs, an example being the cortex implementation suggested by **Dave Raggett on his conference**, which is using computer science technologies like neural networks or graph databases to reproduce a cognitive mecanism for AI models. As reminded in **The Verge**, chatbots are trained this way, by learning on a huge dataset of human made content, and try to reproduce them when asked, each time closer to what a human would make as technology evolves.

While immitating humans can benefit the end user in many ways, this mecanism also have some fitfalls. The same article from **The Verge** also covers some of the nefast consequences this mimetism could have. The most obvious one being the important influence a human-like interlocutor can have on users, misleading them towards an incorrect vision of the world, build upon incorrect informations and biased point of views. Furthermore, designing an AI to make it look sentient echos the question raised by the **Pygmalion play review**: is the creator of this AI truly inventing an independant intelligence, or putting together a reflection of their own ideals, with the limitations and illusions involved ?
