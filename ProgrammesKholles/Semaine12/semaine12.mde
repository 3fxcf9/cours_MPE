# Semaine 12

:date 15/12/2025

## Dérivée du déterminant

Si $M: E_{1} \times  \cdots \times E_{p} \longrightarrow F$ est une application $p$-linéaire avec $E_{1}, \ldots, E_{p}$ et $F$ des $\K$-espaces vectoriels normés de dimension finie, et si $g_{1}: I\longrightarrow E_{1}, \ldots, g_{p}: I\longrightarrow E_{p}$ sont des arcs dérivables en $t_{0}$, alors
$$
  « M(g_1, \ldots, g_{p}) » : \applic{I}{F}{t}{M(g_{1}(t), \ldots, g_{p}(t))}
$$
est dérivable en $t_{0}$ et
$$
  (M(g_{1}, \ldots, g_{p}))'(t_{0}) = \sum_{i=1}^{p}M(g_{1}(t_{0}), \ldots, g_{i-1}(t_{0}), g_{i}'(t_{0}), g_{i+1}(t_{0}), \ldots, g_{p}(t_{0}))
$$

%proof
  On a
  $$
    \begin{align*}
      \frac{M(g_{1}(t), \ldots, g_{p}(t) - M(g_{1}(t_{0}), \ldots, g_{p}(t_{0})))}{t-t_{0}} &= \frac{1}{t-t_{0}}\sum_{i=1}^{p}M(g_{1}(t_{0}), \ldots, g_{i-1}(t_{0}), g_{i}(t)-g_{i}(t_{0}), g_{i+1}(t), \ldots, g_{p}(t))\\
      &=\sum_{i=1}^{p} M(g_{1}(t_{0}), \ldots, g_{i-1}(t_{0}), \frac{g_{i}(t) - g_{i}(t_{0})}{t-t_{0}}, g_{i+1}(t), \ldots, g_{p}(t))
    \end{align*}
  $$
  or
  ~ $\frac{g_{i}(t) - g_{i}(t_{0})}{t-t_{0}}\arrowlim{t\to t_{0}}g_{i}'(t_{0})$  ~ $g_{i+1}(t) \arrowlim{t\to t_{0}}g_{i+1}(t_{0})$  ~ …  ~ $g_{p}(t) \arrowlim{t\to t_{0}}g_{p}(t_{0})$  ~ $M$ est continue (forme $p$-linéaire sur un produit d’espaces vectoriels de dimension finie)
  d’où la dérivabilité de $M(g_{1}, \ldots, g_{p})$ et la formule annoncée.
%

%eg
  Application au déterminant : Si $f_{1}: I \longrightarrow E, \ldots, f_{n}: I \longrightarrow E$ sont $n$ arcs dérivables en $t_{0} \in I$ à valeurs dans $E$ de dimension $n$ muni d’une base $\B$, alors
  $$
    t \longmapsto \det_{\B} (f_{1}(t), \ldots, f_{n}(t))
  $$
  est dérivable en $t_{0}$ et
  $$
    \left(\det_{\B}(f_{1}, \ldots, f_{n})\right)'(t_{0}) = \sum_{i=1}^{n}\det_{\B}(f_{1}(t), \ldots, f_{i}'(t_{0}), \ldots, f_{n}(t_{0}))
  $$
  car $\det_{\B}$ est n-linéaire.
%

## Différentiabilité d’une application multilinéaire

%prop Différentiabilité d’une application multilinéaire
  Si $M: E_{1} \times  \cdots \times E_{p} \longrightarrow F$ est une application $p$-linéaire, alors $M$ est différentiable en tout point $(a_{1}, \ldots, a_{p})\in E_{1} \times  \cdots \times E_{p}$ et
  $$
    \dd M(a_{1}, \ldots, a_{p}): \applic{E_{1} \times  \cdots \times E_{p}}{F}{(h1, \ldots, h_{p})}{\displaystyle\sum_{i=1}^{p}M(a_{1}, \ldots, a_{i-1}h_{i}, a_{i+1}, \ldots, a_{p})}
  $$
%

%proof
  Soit $(a_{1}, \ldots, a_{p})\in E_{1} \times  \cdots \times E_{p}$.
  $$
    M(a_{1}+h_{1}, \ldots, a_{p}+h_{p}) - M(a_{1}, \ldots, a_{p}) = \sum_{i=1}^{p}M(a_{1}, \ldots, a_{i-1}, \underbrace{a_{i}+h_{i}-a_{i}}_{h_{i}}, a_{i+1}+h_{i+1}, \ldots, a_{p}+h_{p})
  $$
  donc
  $$
    M(a+h)-M(a) = \sum_{i=1}^{p}M(a_{1}, \ldots, a_{i-1}, h_{i}, a_{i+1}, \ldots, a_{p}) + S
  $$
  où $S$ est une somme finie de termes de la forme $M(a'_{1}, \ldots, a'_{p}) = \alpha$ avec $\forall i \in \icc{1,p}, a'_{i} \in \{a_{i}, h_{i}\}$.
  $$
    \exists (i,j) \in \icc{1,p}^{2}: i\ne j \text{ et } a'_{i} = h_{i} \text{ et }a'_{j} = h_{j}
  $$
  donc
  $$
    \norm{\alpha}_{F} \leq K \norm{a'_{1}}_{E_{1}}\times  \cdots \times  \norm{a'_{p}}_{E_{p}} \leq K N_{\infty}(h_{1}, \ldots, h_{p})^{2} N_{\infty}(h_{1}, \ldots, h_{p}) \times N_{\infty}(a_{1}, \ldots, a_{p})^{2}
  $$
  et
  $$
    \frac{\alpha}{N_{\infty}(h_{1}, \ldots, h_{p})}\arrowlim{(h_{1}, \ldots, h_{p})\to (0_{E_{1} \times  \cdots \times E_{p}})}0_{F}
  $$
  donc $S = o \big((h_{1}, \ldots, h_{p})\big)$.
%

## Dérivation le long d’un arc

%prop
  Soit $f: U \longrightarrow F$ différentiable en tout point de $U$. Soit $\gamma: I \longrightarrow  E$ un arc tracé sur $U$ et dérivable sur un intervalle $I$ d’intérieur non vide.
  %fig Dérivation le long d’un arc
    @[./figures/dérivation-le-long-d-un-arc_optimized.svg]
  %
  Alors l’arc $f\circ \gamma: I \longrightarrow F$ est dérivable sur $I$ et
  $$
    \forall t \in I, \underbrace{(f\circ \gamma)'(t)}_{\in F} = \underbrace{\dd f(\gamma(t))}_{\in \L(E,F)}\mdot \underbrace{\gamma'(t)}_{\in E}
  $$
  ($\dd f(\gamma(t))$ est l’application linéaire tangente à $f$ en $\gamma(t)$, ou différentielle de $f$ en $\gamma(t)$).
%

%proof
  Soit $t_{0} \in I$. $f$ est différentiable en $\gamma(t_{0}) \in U$ donc
  $$
    \forall x \in U, f(x) = f(\gamma(t_{0})) + \dd f(\gamma(t_{0}))\mdot (x-y(t_{0})) + \norm{x-\gamma(t_{0})}\varepsilon(x)
  $$
  avec $\varepsilon(x) \arrowlim{x\to \gamma(t_{0})}0_{F}$. Or $\forall t \in I, \gamma(t) \in U$ donc
  $$
    \forall t \in I, f(\gamma(t)) = f(\gamma(t_{0})) + \dd f(\gamma(t_{0}))\mdot (\gamma(t) - \gamma(t_{0})) + \norm{\gamma(t) - \gamma(t_{0})}\varepsilon(\gamma(t))
  $$
  Soit $t \in I \setminus \{t_{0}\}$.
  $$
    \frac{f(\gamma(t)) - f(\gamma(t_{0}))}{t-t_{0}} = \underbrace{\dd f(\gamma(t_{0}))\mdot \frac{\gamma(t)-\gamma(t_{0})}{t-t_{0}}}_{\arrowlim{t\to t_{0}}\dd f(\gamma(t_{0}))\mdot \gamma'(t_{0})} + \underbrace{\frac{\norm{\gamma(t) - \gamma(t_{0})}}{t-t_{0}}}_{\arrowlim{t\to t_{0}^{\pm}}\norm{\gamma'(t_{0})}}\underbrace{\varepsilon(\gamma(t))}_{\arrowlim{t\to t_{0}}0_{F}}
  $$
  donc $t \longmapsto (f\circ \gamma)(t)$ est dérivable en $t_{0}$ et
  $$
    (f\circ \gamma)'(t_{0}) = \dd f(\gamma(t_{0}))\mdot \gamma'(t_{0})
  $$
%


## Caractérisation des fonctions constantes

%prop
  Soit $U$ un ouvert non vide convexe par arcs de $E$. Soit $f: U \longrightarrow F$ une application. Alors $f$ est constante si et seulement st
  ~ $f: U \longrightarrow F$ est différentiable sur $U$  ~ $\forall x \in U, \dd f(x) = 0_{\L(E,F)}$
%

%proof
  - Le sens direct est connu
  - Supposons $f:U \longrightarrow F$ différentiable sur $U$ connexe par arcs et telle que $\forall x \in U, \dd f(x) = 0_{\L(E,F)}$.
    - Si $U$ est convexe, soit $(a,b) \in U^{2}$. Comme $U$ est convexe, on a $\cc{a,b} \subset U$. $\gamma: \applic{\cc{0,1}}{U}{t}{a+t(b-a)}$ est dérivable sur $\cc{0,1}$ donc $t \longmapsto (f\circ \gamma)(t)$ est dérivable sur $\cc{0,1}$ et
      $$
        \forall t \in \cc{0,1}, (f\circ \gamma)'(t) = \dd f(\gamma(t)) \mdot \gamma'(t) = 0_{\L(E,F)}\mdot \gamma'(t) = 0
      $$
      donc $f\circ \gamma$ est un arc constant, donc $f(\gamma(1)) = f(\gamma(0))$, i.e. $f(b) = f(a)$.
    - Sinon, $U$ est connexe par arcs. Soit $a \in U$. Comme $U$ est ouvert, il existe $\varepsilon > 0$ tel que $B(a, \varepsilon) \subset U$. On a $\forall x \in U, \dd f(x) = 0$ donc $\forall x \in B(a, \varepsilon), \dd f(x) = 0$ or $B(a, \varepsilon)$ est convexe, donc $f$ est constante sur $B(a, \varepsilon)$. $f$ est donc localement constante sur $U$ convexe par arcs, donc (exercice 11), $f$ est constante sur $U$.
%

## Composition des applications différentiables

%prop
  Soient $E$, $F$ et $G$ trois $\R$-espaces vectoriels normés de dimensions finies. Soient
  ~ $f: U \longrightarrow F$ différentiable en $a \in U$, $U$ ouvert de $E$
  ~ $f(U)\subset V$ avec $V$ ouvert de $E$
  ~ $g: V \longrightarrow G$ différentiable en $f(a)\in V$
  Alors, $g\circ f \longrightarrow G$ est différentiable en $a$ et
  $$
    \underbrace{\dd (g\circ f)(a)}_{\in \L(E,G)} = \underbrace{\dd g(f(a))}_{\in \L(F,G)}\circ \underbrace{\dd f(a)}_{\in \L(E,F)}
  $$
%

%proof
  $$
    f(a+h) = f(a) + \dd f(a)\mdot h + \norm{h}_{E} \varepsilon_{1}(h)
  $$
  avec $\varepsilon_{1}: B_{E}(0_{F}, \delta_{2}) \longrightarrow G$ et $\lim_{x\to 0_{F}}\varepsilon_{2}(x) = 0_{G}$. Or $\dd f(a)\mdot h + \norm{h}_{E} \varepsilon_{1}(h) \arrowlim{h\to 0_{E}}0_{F}$ donc il existe $\delta \in \oo{0,\delta_{1}}$ tel que
  $$
    \forall h \in B_{E}(0_{E}, \delta), K = \dd f(a)\mdot h+\norm{h}_{E} \varepsilon_{1}(h) \in B_{F}(0_{F}, \delta_{2})
  $$
  D’où, pour tot $h \in B_{E}(0_{E}, \delta)$,
  $$
    \begin{align*}
      (g\circ f)(a+h) &= g(f(a+h))\\
       &= g(f(a) + K)\\
        &= g(f(a)) + \dd g(f(a))\mdot K + \norm{K}_{F}\varepsilon_{2}(K)\\
        &= g(f(a)) + \underbrace{\dd g(f(a))\mdot \big(\dd f(a)\mdot h\big)}_{\big(\dd g(f(a))\circ \dd f(a)\big)\mdot h}+ \underbrace{\norm{h}_{E} \dd g(f(a))\mdot \varepsilon_{1}(h)}_{o(h)} + \norm{K}_{F} \varepsilon_{2}(K)
    \end{align*}
  $$
  or
  $$
    \norm{K}_{F} \norm{\varepsilon_{2}(K)}_{G} \leq \big(\underbrace{\opnorm{\dd f(a)} \norm{h}_{E} + \norm{h}_{E} \norm{\varepsilon_{1}(h)}_{F}}_{\norm{h} \big(\opnorm{\dd f(a)} + \norm{\varepsilon_{1}(h)}_{F}\big)}\big)\underbrace{\norm{\varepsilon_{2}(K)}_{G}}_{\arrowlim{h\to 0_{E}}0} = \norm{h} \eta (h)
  $$
  avec $\eta(h)\arrowlim{h\to 0_{E}}0$. Ainsi, $\norm{K}\varepsilon_{2}(K) \ueq{h\to 0_{F}} o(h)$.
%
